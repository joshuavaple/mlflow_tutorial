{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "import numpy as np\n",
    "from setfit import SetFitModel, SetFitTrainer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4208281e2fd24be9af6d5fcee6f0dbc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/2.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a2b1ef438a944b4b68e5e42c9cfc44f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b16940baf34f01aa0d85b39b8a147e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/93.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b3b98912a64866ac35415bb7b4e2ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/42.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45beeadddb940f9980647e3a2b1cf4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/42.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a7312a7372044d59061200a1eb1681e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "207512e954544a8eb477b866ac8acdad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/540 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549af7f2441b4677b375e5c96f2ff1d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/180 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75d67ecece34589b0f288368aeed900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating valid split:   0%|          | 0/180 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"joshuapsa/gpt-generated-news-paragraphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"SetFit/SentEval-CR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['* slick-looking design and improved interface', \"the day finally arrived when i was sure i 'd leave sprint .\", 'as for bluetooth , no problems at all .', '2 ) storage capacity', \"neither message was answered ( they ask for 24 hours before replying - i 've been waiting 27 days . )\", \"for a price that 's still less than even the lowest level ipod i was able to get this 40gb monster , and the best part is it works as great as it was advertised to and then some .\", 'i bought the player this week and i like it by far .', 'only problem is that is a bit heavy .', 'i love the slim design ; . the weight would only be an issue if it were bulky .', 'it fits into a hand well , it has a removable battery ( this is important ) , great sound quality , fm stereo , recorder , smooth ui , and a feature that most uni pods lack . . . char ! .', 'once a depth is locked , it will jump off a little while working .', 'the thought of not having to buy refills and just using regular bags is awesome ! .', 'where close to 12 hours but at least it is replaceable ( and they included a second one free ) .', \"took me a few tries to get use to the navigation , but it 's a very user friendly player imo .\", \"the pc-side software can be goofy and takes a little getting used to but it 's not as bad as some reviewers have indicated .\"]\n",
      "[1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "train_ds = dataset[\"train\"].shuffle(seed=42).select(range(8 * 2))\n",
    "print(train_ds['text'][:15])\n",
    "print(train_ds['label'][:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.arrow_dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "# check the type of the 2 datasets:\n",
    "print(type(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load SetFit model from Hub\n",
    "model = SetFitModel.from_pretrained(\"sentence-transformers/paraphrase-mpnet-base-v2\")\n",
    "\n",
    "# Create trainer\n",
    "trainer = SetFitTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    loss_class=CosineSimilarityLoss,\n",
    "    batch_size=16,\n",
    "    num_iterations=20, # Number of text pairs to generate for contrastive learning\n",
    "    num_epochs=1 # Number of epochs to use for contrastive learning\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d45f67e26b244b99b81350d809261d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Training Pairs:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 640\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 40\n",
      "  Total train batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0c9663f8b644baa364aff8a6feef94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0af36dc737084eda86361570b729a9c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate!\n",
    "trainer.train()\n",
    "metrics = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_body': SentenceTransformer(\n",
       "   (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "   (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       " ),\n",
       " 'model_head': LogisticRegression(),\n",
       " 'multi_target_strategy': None,\n",
       " 'l2_weight': 0.01,\n",
       " 'normalize_embeddings': False}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0], dtype=torch.int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model([\"i loved the spiderman movie!\", \"pineapple on pizza is the worst ðŸ¤®\"])\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2417, 0.7583],\n",
       "        [0.7358, 0.2642]], dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.predict([\"i loved the spiderman movie!\", \"pineapple on pizza is the worst ðŸ¤®\"])\n",
    "model.predict_proba([\"i loved the spiderman movie!\", \"pineapple on pizza is the worst ðŸ¤®\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Multi Label Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"sentence-transformers/paraphrase-mpnet-base-v2\"\n",
    "dataset_ml = load_dataset(\"ethos\", \"multilabel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'violence', 'directed_vs_generalized', 'gender', 'race', 'national_origin', 'disability', 'religion', 'sexual_orientation'],\n",
       "        num_rows: 433\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#note that there is no \"test\" nor \"validate\" for this dataset out from the box\n",
    "# (since the ethos dataset does not have a test split on the hub).\n",
    "dataset_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"You should know women's sports are a joke\", 'You look like Sloth with deeper Downâ€™s syndrome', 'You look like Russian and speak like Indian. Both are disgusting go kill yourself', 'Women deserve to be abused, I guess.', 'Women are made for making babies and cooking dinner and nothing else!!!']\n",
      "[1, 0, 0, 1, 1]\n",
      "['violence', 'directed_vs_generalized', 'gender', 'race', 'national_origin', 'disability', 'religion', 'sexual_orientation']\n"
     ]
    }
   ],
   "source": [
    "# exploring the dataset:\n",
    "# the text data -> this is a list of strings\n",
    "print(dataset_ml['train']['text'][:5])\n",
    "\n",
    "# in this case, the classes are already transformed into one-hot columns\n",
    "# where each column represents a class label\n",
    "# e.g., the 1st, 4th and 5th articles are about 'gender'\n",
    "print(dataset_ml['train']['gender'][:5])\n",
    "\n",
    "# we can list the classes a.k.a \"features\":\n",
    "features = dataset_ml[\"train\"].column_names\n",
    "features.remove(\"text\")\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6, 7, 8, 9], dtype=int64),)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(10,20)\n",
    "np.where(a) # returns the indices of all elements in a\n",
    "np.where(a>15) # returns the indices of the elements in a meeting the condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([206, 291, 300,  65, 420,  28, 411, 228,   6, 321,   8, 408, 378,\n",
       "        90,  67, 353, 101, 360, 406, 250, 388, 378, 423, 353,  35, 206,\n",
       "        19, 305, 169,  24, 199,  16, 156,  91, 252, 263, 314, 277, 235,\n",
       "       325, 100, 200, 422, 229, 162, 288,  73, 140, 241, 419, 303, 120,\n",
       "        38, 189,  99, 308, 176, 133, 397,  77, 427, 222,  36,  90],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To simulate the effect of training on a limited number of examples, \n",
    "# let's subsample the training set to have at least 8 labeled examples per feature.\n",
    "num_samples = 8\n",
    "samples = np.concatenate(\n",
    "    [np.random.choice(np.where(dataset_ml[\"train\"][f])[0], num_samples, replace=False) for f in features]\n",
    ")\n",
    "print(samples.shape)\n",
    "samples # this is an array of indices of 8 records per feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewritten for better clarity:\n",
    "# import collections\n",
    "\n",
    "# sample_list = []\n",
    "# for f in features:\n",
    "#     print(f)\n",
    "#     # get all the indices of the records belonging to this feature:\n",
    "#     indices = np.where(dataset_ml[\"train\"][f])[0] # using [0] to get the value of the tuple returned from np.where\n",
    "#     print(indices)\n",
    "#     sample = np.random.choice(indices,num_samples, replace=False)\n",
    "#     print('duplicated item in a sample of a class:')\n",
    "#     print([item for item, count in collections.Counter(list(sample)).items() if count > 1])\n",
    "#     sample_list.append(sample)\n",
    "# samples = np.concatenate(sample_list)\n",
    "# samples\n",
    "# len(samples) == len(set(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list = list(samples)\n",
    "# duplicated_list = list(samples)\n",
    "# unique_list = list(set(samples))\n",
    "# print(sorted(duplicated_list))\n",
    "# print([item for item, count in collections.Counter(duplicated_list).items() if count > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 0, 0, 0, 0, 0]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# We encode the classes one-hot values in a single 'label' feature\n",
    "# returns a dictionary\n",
    "def encode_labels(record):\n",
    "    return {\"labels\": [record[feature] for feature in features]}\n",
    "\n",
    "\n",
    "# this will act on all the records of the dataset object and create a new \"column\" called \"labels\"\n",
    "# effectively, this is equivalent to dataframe['labels'] = dataframe.apply(lambda row: encode_labels(row))\n",
    "dataset_ml = dataset_ml.map(encode_labels) \n",
    "print(dataset_ml['train']['labels'][0])\n",
    "print(dataset_ml['train']['gender'][0]) # 'gender is the index #2 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset_ml[\"train\"].select(samples) # pass the array of indices above to select\n",
    "eval_dataset = dataset_ml[\"train\"].select(\n",
    "    np.setdiff1d(np.arange(len(dataset_ml[\"train\"])), samples)\n",
    ") # find the difference in 2 arrays: indices of the samples, and indices of the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Note that the multi_target_strategy parameter here signals to both the model and the trainer \n",
    "# to expect a multi-labelled dataset.\n",
    "# Here, we've downloaded a pretrained Sentence Transformer from the Hub \n",
    "# and added a logistic classification head to the create the SetFit model.\n",
    "model_ml = SetFitModel.from_pretrained(model_id, # use any Sentence transformer model\n",
    "                                    multi_target_strategy=\"one-vs-rest\" \n",
    "                                    )\n",
    "# note that we can load a locally available model by using a\n",
    "# path to a `directory` containing model weights saved using\n",
    "# [`~transformers.PreTrainedModel.save_pretrained`], e.g., `../path/to/my_model_directory/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneVsRestClassifier(estimator=LogisticRegression())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneVsRestClassifier</label><div class=\"sk-toggleable__content\"><pre>OneVsRestClassifier(estimator=LogisticRegression())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression())"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that the logistic regression head is added by default by SetFitModel class\n",
    "model_ml.model_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can initialize the trainer to configure how we want to train the model:\n",
    "# note `column_mapping` argument: The SetFitTrainer expects the inputs to be found in a \"text\" and \"label\" column. \n",
    "# This mapping automatically formats the training and evaluation datasets for us.\n",
    "trainer = SetFitTrainer(\n",
    "    model=model_ml,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    loss_class=CosineSimilarityLoss,\n",
    "    num_iterations=5,\n",
    "    column_mapping={\"text\": \"text\", \"labels\": \"label\"}, # IMPORTANT for SetFit - hardcoded in the source code\n",
    "    num_epochs=1,\n",
    "    batch_size=5\n",
    ")\n",
    "\n",
    "# trainer = SetFitTrainer(\n",
    "#     model=model,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=eval_dataset,\n",
    "#     loss_class=CosineSimilarityLoss,\n",
    "#     # batch_size=16,\n",
    "#     num_iterations=20, # Number of text pairs to generate for contrastive learning\n",
    "#     num_epochs=1, # Number of epochs to use for contrastive learning\n",
    "#     # column_mapping={\"text\": \"text\", \"labels\": \"label\"}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying column mapping to training dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca3a18c52804c94ac9f503bc8a38172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Training Pairs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 940\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 188\n",
      "  Total train batch size = 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "219d778cdc4a449496723e663faf3d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fda205f9b3b44ee90caf87da5e80403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# with the trainer configured, we can now train the model proper:\n",
    "# np.random.seed()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying column mapping to evaluation dataset\n",
      "***** Running evaluation *****\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.3967828418230563}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['violence',\n",
       " 'directed_vs_generalized',\n",
       " 'gender',\n",
       " 'race',\n",
       " 'national_origin',\n",
       " 'disability',\n",
       " 'religion',\n",
       " 'sexual_orientation']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:\n",
      "['violence', 'directed_vs_generalized', 'gender', 'race', 'national_origin', 'disability', 'religion', 'sexual_orientation']\n",
      "predicted class label: \n",
      "['race', 'national_origin', 'religion']\n",
      "details:\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 0]], dtype=torch.int32)\n",
      "tensor([[0.0054, 0.2941, 0.1928, 0.3491, 0.0103, 0.0084, 0.0033, 0.0576],\n",
      "        [0.2756, 0.0135, 0.0365, 0.0146, 0.5041, 0.1338, 0.0457, 0.0099],\n",
      "        [0.1776, 0.0114, 0.0261, 0.0128, 0.0430, 0.0154, 0.9251, 0.0056]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "sample_texts = ['men tend to be more interested in things and women more in people, but this may be different across races',\n",
    "                'Ukraine is in a long war that has led to millions displaced',\n",
    "                'Christianity is the largest religion in the world'\n",
    "                ]\n",
    "preds = model_ml.predict(sample_texts)\n",
    "pred_probas = model_ml.predict_proba(sample_texts)\n",
    "\n",
    "print(\"labels:\")\n",
    "print(features)\n",
    "print(\"predicted class label: \")\n",
    "print([features[int(pred_proba.argmax())] for pred_proba in pred_probas]) # somehow pred does not always give a class prediction -> can be a zeros array(???)\n",
    "\n",
    "print('details:')\n",
    "print(preds)\n",
    "print(pred_probas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Getting from pre-trained and check details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JOSHUALE\\Documents\\Github\\mlflow_tutorial\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.1.3 when using version 1.3.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\JOSHUALE\\Documents\\Github\\mlflow_tutorial\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator LabelBinarizer from version 1.1.3 when using version 1.3.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\JOSHUALE\\Documents\\Github\\mlflow_tutorial\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator OneVsRestClassifier from version 1.1.3 when using version 1.3.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from setfit import SetFitModel\n",
    "\n",
    "setfit_model = SetFitModel.from_pretrained(\"lewtun/setfit-ethos-multilabel-example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the setfit model can be used as is but we need to know the labels and their sequences which were used to train this particular model\n",
    "preds = setfit_model(\n",
    "    [\n",
    "        \"Jewish people often don't eat pork.\",\n",
    "        \"Is this lipstick suitable for people with dark skin?\"\n",
    "    ]\n",
    ")\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_body': SentenceTransformer(\n",
       "   (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "   (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       " ),\n",
       " 'model_head': OneVsRestClassifier(estimator=LogisticRegression()),\n",
       " 'multi_target_strategy': None,\n",
       " 'l2_weight': 0.01,\n",
       " 'normalize_embeddings': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# behind the scene, the model is of SentenceTransformer class\n",
    "# when taking the model_body, it has the same methods as a normal ST model such as encoding a text\n",
    "setfit_model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.93167713e-02,  3.17766182e-02, -4.10573892e-02,  5.57808280e-02,\n",
       "        9.08400640e-02, -1.77587401e-02, -1.36027306e-01, -1.47274258e-02,\n",
       "        1.59128204e-01,  1.16944551e-01, -4.62600812e-02,  2.98268616e-01,\n",
       "       -5.22914454e-02, -8.29667673e-02, -4.44911234e-02, -4.40300219e-02,\n",
       "        1.66153476e-01,  1.91608459e-01,  4.12492529e-02, -2.89649013e-02,\n",
       "       -1.03310630e-01,  1.47008151e-01,  1.29550248e-01, -3.77085879e-02,\n",
       "       -2.10230798e-01, -1.06654964e-01,  9.99176949e-02,  1.21255957e-01,\n",
       "        1.41623139e-01,  3.66448388e-02,  1.32339492e-01,  1.83584392e-02,\n",
       "       -2.79984921e-01,  1.19764067e-01,  9.95515436e-02,  1.32437855e-01,\n",
       "        1.01705149e-01,  3.26256976e-02, -1.57782301e-01,  1.11090027e-01,\n",
       "        9.38620195e-02,  4.56442982e-02, -1.28066212e-01,  9.21679754e-03,\n",
       "       -2.83422321e-02, -5.04130051e-02,  1.33230761e-01, -3.63847166e-02,\n",
       "        1.81325838e-01, -9.41544920e-02, -3.93210240e-02, -3.06797773e-02,\n",
       "        1.67208649e-02,  8.84119272e-02, -3.77369532e-03,  8.32832232e-02,\n",
       "       -6.14553094e-02,  6.87301978e-02,  1.54787317e-01,  7.14623854e-02,\n",
       "        1.04052626e-01, -2.62120664e-01,  5.44435196e-02, -8.60746950e-02,\n",
       "       -2.17572168e-01,  2.27980921e-03,  1.82251126e-01, -1.48413479e-01,\n",
       "        2.14961953e-02,  6.92388276e-03,  7.94767588e-02,  9.46198180e-02,\n",
       "       -6.91609979e-02,  2.65654474e-01, -1.90774146e-02, -1.22345462e-01,\n",
       "        1.12413071e-01, -8.50751847e-02, -1.28869470e-02,  9.41280425e-02,\n",
       "        1.62221298e-01,  1.96682494e-02, -2.71834377e-02,  1.01289973e-01,\n",
       "       -8.45459551e-02,  4.58013304e-02,  4.75780219e-02, -4.67098430e-02,\n",
       "        2.04633683e-01, -1.92302078e-01, -6.98518604e-02, -4.62112799e-02,\n",
       "       -8.28603581e-02, -1.58291515e-02, -8.38419348e-02, -1.87086359e-01,\n",
       "        3.80218960e-02,  1.65422231e-01,  6.25125617e-02, -7.80872926e-02,\n",
       "       -8.46426263e-02, -2.68648565e-02, -1.43422097e-01, -5.96884266e-03,\n",
       "        2.17280630e-02, -1.59915596e-01, -5.82793467e-02,  4.97249663e-02,\n",
       "       -2.34416753e-01, -1.82620827e-02,  5.22615500e-02, -1.73194781e-02,\n",
       "       -6.77172020e-02,  1.61747545e-01,  1.68998558e-02, -9.00185257e-02,\n",
       "        1.91433392e-02,  7.44667929e-03, -1.63449392e-01, -1.53780580e-01,\n",
       "        1.94920897e-01,  5.42461164e-02, -1.94521204e-01, -3.36237177e-02,\n",
       "        1.74176842e-02,  1.28989518e-01, -3.27239573e-01,  2.24270061e-01,\n",
       "       -9.18221325e-02,  1.15003191e-01, -5.19877896e-02,  7.24157542e-02,\n",
       "       -5.06628975e-02,  1.66607141e-01,  1.08179614e-01, -4.19420078e-02,\n",
       "        6.50383756e-02,  5.52798882e-02, -2.46365026e-01, -2.39561535e-02,\n",
       "       -3.15776542e-02,  7.18766078e-02, -2.07377315e-01, -5.01382118e-03,\n",
       "       -1.82237357e-01, -8.88682380e-02,  1.17540825e-02, -6.23790994e-02,\n",
       "       -4.79981527e-02,  1.92952856e-01,  4.93068853e-03, -3.98540217e-03,\n",
       "       -5.67453317e-02,  5.54131158e-02, -9.47335921e-03, -8.74496922e-02,\n",
       "        3.64748910e-02, -1.63011536e-01,  3.32050547e-02,  2.41290182e-01,\n",
       "       -4.49455418e-02,  3.20581123e-02, -2.68455688e-02,  1.06282458e-01,\n",
       "       -2.15418130e-01, -1.10070646e-01, -7.07072467e-02, -5.92835620e-02,\n",
       "       -1.33648187e-01, -1.74195156e-01,  1.79790554e-03,  3.37063879e-01,\n",
       "       -1.75684154e-01, -1.40756937e-02,  3.19464147e-01, -5.95962293e-02,\n",
       "       -1.10607766e-01,  1.17099926e-01, -1.55887023e-01, -2.34491825e-01,\n",
       "       -8.33974704e-02,  5.56795895e-02,  1.77260444e-01,  1.30755410e-01,\n",
       "       -2.26731941e-01,  7.08622113e-02, -2.18189284e-01,  4.97308560e-02,\n",
       "       -1.75180025e-02, -6.17927825e-03,  5.14204502e-02, -1.27679080e-01,\n",
       "       -9.22084451e-02,  1.08709261e-01, -2.44332459e-02,  1.36068240e-01,\n",
       "        6.44380227e-02, -8.50772634e-02,  2.63305064e-02,  1.15569964e-01,\n",
       "       -1.57359153e-01, -9.62084979e-02,  2.00816318e-01,  5.74319670e-03,\n",
       "       -7.81346560e-02,  1.35219783e-01,  6.52321354e-02, -1.93946794e-01,\n",
       "        3.21844704e-02,  2.12519430e-03,  1.00936033e-01, -1.15258731e-01,\n",
       "        5.23639545e-02,  2.29896381e-01,  2.02069968e-01, -5.31719811e-02,\n",
       "        1.18062019e-01,  1.67604700e-01,  4.40817252e-02,  2.35461161e-01,\n",
       "       -1.37367100e-01,  8.74256045e-02,  2.34275967e-01, -5.28838411e-02,\n",
       "       -2.13443398e-01, -1.19743302e-01,  1.09508559e-01, -1.70494877e-02,\n",
       "        1.91968270e-02, -3.87329906e-02, -8.32862481e-02, -4.20482159e-02,\n",
       "        8.56145769e-02, -4.07333523e-02,  2.04125911e-01,  2.87459373e-01,\n",
       "        1.52774885e-01,  1.19033851e-01,  2.34786607e-03, -1.89460278e-01,\n",
       "        8.38687941e-02,  8.93730521e-02,  1.73717171e-01, -3.46954283e-03,\n",
       "        1.46551952e-02, -1.32915691e-01,  9.53386948e-02, -5.10182604e-02,\n",
       "       -7.32568949e-02, -1.23076200e-01, -3.06732301e-02,  1.53298661e-01,\n",
       "        7.21141845e-02, -6.15713187e-02,  4.67742011e-02, -5.73637374e-02,\n",
       "       -7.84385055e-02, -3.00509091e-02,  2.48068660e-01,  4.36289087e-02,\n",
       "        7.83055574e-02,  3.21147256e-02,  1.60087615e-01, -1.48613125e-01,\n",
       "        1.58086047e-01,  2.57976614e-02, -9.16094109e-02, -1.40495360e-01,\n",
       "        2.46157758e-02, -3.62905040e-02, -5.97845344e-03,  5.51707819e-02,\n",
       "        8.76294374e-02, -2.23173052e-02,  7.22740293e-02,  1.21353470e-01,\n",
       "       -7.48995692e-02, -1.61965936e-01, -9.47885402e-03, -3.23884748e-02,\n",
       "       -5.40573671e-02, -1.43972903e-01,  9.52630639e-02,  1.83897048e-01,\n",
       "        4.77948412e-02,  3.66822642e-04, -1.24403939e-01,  2.52011660e-02,\n",
       "        6.91948086e-02, -1.24834970e-01,  2.32365951e-02,  9.93562415e-02,\n",
       "       -3.46646607e-02,  2.47074991e-01,  1.24840021e-01, -2.18900181e-02,\n",
       "       -5.67361936e-02,  1.25601977e-01, -1.68584496e-01, -2.20976733e-02,\n",
       "       -3.05072255e-02, -1.12528943e-01,  2.79290671e-03,  9.89037007e-02,\n",
       "        3.93177941e-02,  8.56019929e-03, -2.36131512e-02, -2.69060045e-01,\n",
       "        1.29603848e-01,  2.56479770e-01,  2.01333001e-01,  1.10623814e-01,\n",
       "        1.27149239e-01,  5.76864481e-02,  3.02436594e-02,  6.04412444e-02,\n",
       "       -8.23799223e-02,  7.84488395e-03,  9.21027921e-03,  2.82185495e-01,\n",
       "       -2.34849602e-02, -2.98057258e-01,  7.74901286e-02, -2.68548071e-01,\n",
       "        3.19194719e-02,  1.07702538e-01,  6.85781986e-02,  1.97264347e-02,\n",
       "        2.26628989e-01, -5.02836779e-02, -6.83872262e-03,  2.58150343e-02,\n",
       "        2.18967229e-01,  2.93258373e-02,  1.12041965e-01,  5.70725929e-03,\n",
       "       -1.25509724e-01, -1.22040207e-03, -1.35353521e-01, -4.29289006e-02,\n",
       "        1.24802791e-01, -1.10661820e-01,  1.99953886e-03,  6.72730710e-03,\n",
       "       -4.15717453e-01, -9.62176695e-02,  1.91155836e-01,  6.36757463e-02,\n",
       "       -1.63830191e-01,  8.97150412e-02, -2.13702649e-01,  8.20244551e-02,\n",
       "       -9.39280614e-02, -2.06957310e-01, -1.46246087e-02, -1.45870313e-01,\n",
       "       -7.06379563e-02,  1.48808537e-02, -1.39098316e-01,  2.61579216e-01,\n",
       "        2.81283613e-02, -1.01204157e-01,  8.84403512e-02, -1.28608182e-01,\n",
       "       -8.06492195e-02, -5.74668497e-03,  1.03365779e-01, -3.04090092e-03,\n",
       "        5.89191914e-04,  1.44706983e-02, -5.51056750e-02,  2.06169173e-01,\n",
       "       -9.13102776e-02,  6.64491504e-02,  1.45909395e-02, -8.28477740e-02,\n",
       "        1.09747097e-01,  4.62164804e-02, -5.85519783e-02,  6.33248612e-02,\n",
       "        1.39241725e-01, -7.45497784e-03, -2.59953171e-01, -1.36806101e-01,\n",
       "       -8.65653306e-02, -6.98907441e-03, -5.79571165e-03,  3.47076356e-02,\n",
       "       -3.59760597e-02, -4.75975201e-02,  6.78851604e-02, -3.15078288e-01,\n",
       "       -4.73215058e-02, -8.44159871e-02, -2.22206414e-02, -1.62135556e-01,\n",
       "        5.67944236e-02, -9.31900740e-02, -3.49682719e-02, -6.96227700e-02,\n",
       "       -6.16241246e-03,  2.25466728e-01,  3.41676932e-04,  1.66914612e-01,\n",
       "        4.52768728e-02, -1.26470830e-02,  3.26218545e-01, -1.25729321e-02,\n",
       "       -4.16560378e-03, -3.96970063e-02, -2.15424135e-01, -6.83566406e-02,\n",
       "        1.67285398e-01,  1.26734212e-01, -1.16840519e-01, -2.24156305e-01,\n",
       "        1.61647901e-01, -1.78390101e-01,  6.45773038e-02,  8.34422335e-02,\n",
       "       -7.24460036e-02,  5.20229936e-02, -6.08504936e-02,  8.04800019e-02,\n",
       "       -1.26294822e-01, -9.75420550e-02, -2.33946085e-01,  1.54065132e-01,\n",
       "       -1.11137554e-02,  5.31675704e-02,  6.84358831e-03, -1.17536366e-01,\n",
       "        1.50681704e-01, -2.51801759e-01, -2.35219210e-01, -4.39318307e-02,\n",
       "        2.69754022e-01,  1.53407201e-01, -2.14943200e-01, -8.52899179e-02,\n",
       "       -3.60377319e-02, -7.81186894e-02,  5.84184751e-02,  9.18371603e-02,\n",
       "       -9.09520835e-02,  1.33549362e-01, -5.19317165e-02,  1.19912110e-01,\n",
       "       -1.40269279e-01,  2.15720341e-01, -7.96137899e-02,  1.80434324e-02,\n",
       "        4.02863920e-02,  1.28152937e-01,  7.89121985e-02, -1.07940055e-01,\n",
       "        1.86821356e-01, -1.65180951e-01,  1.12784550e-01, -6.47932515e-02,\n",
       "        2.34622806e-01,  6.65200949e-01,  1.16708398e-01, -2.75592562e-02,\n",
       "       -1.39564425e-01, -5.03765233e-02,  2.34632760e-01,  1.77108109e-01,\n",
       "       -5.73157780e-02,  6.71290373e-03, -7.22667426e-02,  1.07720956e-01,\n",
       "        4.26377133e-02,  9.34510231e-02,  6.51687756e-02,  4.94409874e-02,\n",
       "       -1.22826315e-01, -5.34579232e-02, -8.33789855e-02,  1.16625503e-01,\n",
       "       -2.46632267e-02, -1.37120903e-01, -4.28340323e-02,  2.17217639e-01,\n",
       "        1.68413207e-01, -3.83955911e-02,  8.86535048e-02, -1.37430117e-01,\n",
       "        2.28362873e-01, -4.40850807e-03,  1.13626897e-01, -1.42698973e-01,\n",
       "        4.11835983e-02, -9.64749604e-02, -6.37352914e-02,  8.08435231e-02,\n",
       "       -2.23223135e-01, -5.11945128e-01, -2.28639886e-01,  1.07550666e-01,\n",
       "       -2.14253455e-01, -9.79699865e-02,  3.36784944e-02,  6.31388575e-02,\n",
       "        3.47256064e-02, -5.00012562e-03, -9.72969085e-02,  1.26631349e-01,\n",
       "        5.76345399e-02, -9.44368839e-02, -1.41106965e-02,  1.77876830e-01,\n",
       "       -1.72514290e-01,  3.71055380e-02, -1.35371298e-01,  3.89517136e-02,\n",
       "        2.22890407e-01, -4.24631745e-01,  2.09832907e-01, -4.56252843e-02,\n",
       "        3.54641750e-02, -2.11168285e-02,  1.20821893e-01,  6.59787580e-02,\n",
       "       -8.64836425e-02, -7.54083991e-02, -4.09645066e-02, -1.78875133e-01,\n",
       "       -4.95237038e-02,  3.31784278e-01, -2.84406662e-01, -2.20543191e-01,\n",
       "        1.23417554e-02,  1.47434115e-01, -1.70062900e-01, -3.93328145e-02,\n",
       "       -1.15683794e-01,  2.10296623e-02, -4.10352573e-02, -2.10196942e-01,\n",
       "       -9.29911286e-02, -1.41865835e-01,  5.86398058e-02, -2.96176616e-02,\n",
       "        1.50865123e-01,  1.52890414e-01, -1.45622537e-01,  1.37013957e-01,\n",
       "        1.69519022e-01, -6.02519587e-02,  1.40204251e-01,  1.59157757e-02,\n",
       "       -3.62594634e-01, -2.83899251e-02,  6.72668144e-02, -4.08349447e-02,\n",
       "        3.69175449e-02,  1.08066574e-01, -9.24908370e-02,  1.12660810e-01,\n",
       "        2.20916659e-01, -4.71386407e-03,  1.94630679e-02,  4.79021743e-02,\n",
       "        7.67735466e-02,  8.49892721e-02, -3.09360512e-02, -8.16784278e-02,\n",
       "        8.51656776e-03,  3.88850048e-02,  3.54320626e-03, -1.13030039e-02,\n",
       "       -3.63462046e-02,  2.60177076e-01,  4.64368686e-02, -1.83199402e-02,\n",
       "       -1.74368382e-01,  4.43545869e-03, -4.78136837e-02,  3.38573828e-02,\n",
       "        5.47545683e-03,  4.95042056e-02, -8.92152078e-03, -9.76683274e-02,\n",
       "       -1.03590488e-01,  1.24883533e-01, -3.83839607e-02,  2.00104743e-01,\n",
       "       -4.58341017e-02,  9.37465206e-02,  4.40917127e-02,  3.18430997e-02,\n",
       "        3.86653990e-01,  3.30306701e-02, -1.77352399e-01, -1.85100511e-01,\n",
       "       -9.81774647e-03, -6.20324090e-02,  1.68386966e-01,  1.48720503e-01,\n",
       "       -1.33832367e-02,  2.13370174e-01,  4.66233678e-02,  1.10948280e-01,\n",
       "       -3.11515749e-01,  1.91889238e-02, -9.43113416e-02, -6.93437606e-02,\n",
       "        5.26937023e-02, -2.54618764e-01, -7.68321007e-02,  1.30044326e-01,\n",
       "        2.53990348e-02,  1.99279398e-01,  5.64670190e-03,  2.44789217e-02,\n",
       "       -7.28951097e-02, -2.50107467e-01,  2.41579171e-02, -3.60825583e-02,\n",
       "        1.10054210e-01,  5.72815770e-03, -1.17131993e-01, -6.36710525e-02,\n",
       "        2.59899087e-02,  1.74341977e-01,  1.86596625e-02,  1.03713967e-01,\n",
       "        2.45062783e-01, -1.61909014e-01, -4.78076302e-02, -1.43675711e-02,\n",
       "       -1.71915293e-02,  1.62959129e-01, -1.10044539e-01, -2.70035751e-02,\n",
       "       -2.29182169e-01, -8.14114735e-02, -1.28775924e-01, -1.11027658e-01,\n",
       "        1.74316019e-02,  2.05246493e-01,  8.53014886e-02,  4.80012186e-02,\n",
       "       -3.06866132e-02, -1.10348940e-01, -1.17436089e-01,  2.52286308e-02,\n",
       "       -8.96974578e-02, -4.35567573e-02, -7.31439888e-02, -3.14391077e-01,\n",
       "       -5.10679260e-02, -3.55425254e-02, -1.97501823e-01, -1.53587341e-01,\n",
       "       -1.02804795e-01, -6.98544309e-02, -4.02938761e-02,  1.42678708e-01,\n",
       "        9.47994441e-02,  2.64163921e-03,  5.60458601e-02, -1.44060880e-01,\n",
       "       -1.73820049e-01, -4.70551252e-02, -5.67066893e-02,  4.99687418e-02,\n",
       "       -7.55538568e-02, -3.01864464e-03,  7.31193125e-02, -5.31626754e-02,\n",
       "       -7.94280600e-03,  6.34414405e-02,  1.53152421e-01,  8.40793699e-02,\n",
       "       -9.45743769e-02, -9.71646383e-02, -1.32753756e-02, -2.00929239e-01,\n",
       "        8.40721130e-02,  9.49648470e-02,  9.01160315e-02, -3.93991843e-02,\n",
       "       -3.00612956e-01, -2.17553288e-01,  1.44300458e-03, -1.61546201e-01,\n",
       "        8.67327824e-02, -5.74967042e-02,  7.67198950e-02,  1.03221431e-01,\n",
       "        1.53108835e-01,  3.89478877e-02,  1.06453672e-01,  5.89243658e-02,\n",
       "        5.44453487e-02, -3.20606604e-02, -3.17337871e-01,  4.28261980e-02,\n",
       "       -4.08072993e-02, -7.94251338e-02,  3.73013556e-01, -2.52642810e-01,\n",
       "        1.86119244e-01, -1.97485775e-01,  2.82956474e-02, -5.96106164e-02,\n",
       "       -9.10209119e-02,  1.27474278e-01, -1.45818572e-02,  4.15868275e-02,\n",
       "       -5.64175434e-02,  4.94478978e-02,  4.82310988e-02, -1.09557785e-01,\n",
       "       -1.53327376e-01,  6.34924099e-02, -4.75093052e-02, -2.05704883e-01,\n",
       "        1.32002681e-01, -7.43875727e-02, -4.23775278e-02,  1.18974773e-02,\n",
       "        6.80563077e-02, -4.36447151e-02, -4.36927900e-02, -4.54500876e-02,\n",
       "        1.79783866e-01,  5.79705946e-02,  5.75173870e-02,  6.65712729e-02,\n",
       "        6.20120354e-02,  1.27975360e-01,  6.20930083e-02,  4.08081710e-02,\n",
       "        2.05347568e-01,  1.59526244e-01,  6.55016452e-02,  8.34278241e-02,\n",
       "       -1.05196871e-01,  1.89640671e-01,  1.38763279e-01,  9.58150774e-02,\n",
       "       -3.74795683e-02,  1.61355257e-01,  1.05714843e-01, -1.46287724e-01,\n",
       "       -6.37997165e-02, -3.59080136e-02,  1.26005620e-01,  3.64828221e-02,\n",
       "        1.33744419e-01,  5.65991774e-02,  7.26696700e-02, -1.01960264e-01,\n",
       "       -1.67260438e-01, -1.80588752e-01,  1.91640444e-02,  6.11853786e-02,\n",
       "        1.21914864e-01,  1.26483336e-01,  3.44513245e-02,  2.52465010e-01,\n",
       "        2.36565191e-02,  1.58284735e-02,  1.26289278e-02, -1.76671639e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setfit_encodings = setfit_model.model_body.encode(\"I love apple\")\n",
    "setfit_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "st_model = SentenceTransformer('lewtun/setfit-ethos-multilabel-example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the same model is obtained via calling the pretrained model from the SentenceTransformer module directly\n",
    "st_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 4.93167713e-02,  3.17766182e-02, -4.10573892e-02,  5.57808280e-02,\n",
       "        9.08400640e-02, -1.77587401e-02, -1.36027306e-01, -1.47274258e-02,\n",
       "        1.59128204e-01,  1.16944551e-01, -4.62600812e-02,  2.98268616e-01,\n",
       "       -5.22914454e-02, -8.29667673e-02, -4.44911234e-02, -4.40300219e-02,\n",
       "        1.66153476e-01,  1.91608459e-01,  4.12492529e-02, -2.89649013e-02,\n",
       "       -1.03310630e-01,  1.47008151e-01,  1.29550248e-01, -3.77085879e-02,\n",
       "       -2.10230798e-01, -1.06654964e-01,  9.99176949e-02,  1.21255957e-01,\n",
       "        1.41623139e-01,  3.66448388e-02,  1.32339492e-01,  1.83584392e-02,\n",
       "       -2.79984921e-01,  1.19764067e-01,  9.95515436e-02,  1.32437855e-01,\n",
       "        1.01705149e-01,  3.26256976e-02, -1.57782301e-01,  1.11090027e-01,\n",
       "        9.38620195e-02,  4.56442982e-02, -1.28066212e-01,  9.21679754e-03,\n",
       "       -2.83422321e-02, -5.04130051e-02,  1.33230761e-01, -3.63847166e-02,\n",
       "        1.81325838e-01, -9.41544920e-02, -3.93210240e-02, -3.06797773e-02,\n",
       "        1.67208649e-02,  8.84119272e-02, -3.77369532e-03,  8.32832232e-02,\n",
       "       -6.14553094e-02,  6.87301978e-02,  1.54787317e-01,  7.14623854e-02,\n",
       "        1.04052626e-01, -2.62120664e-01,  5.44435196e-02, -8.60746950e-02,\n",
       "       -2.17572168e-01,  2.27980921e-03,  1.82251126e-01, -1.48413479e-01,\n",
       "        2.14961953e-02,  6.92388276e-03,  7.94767588e-02,  9.46198180e-02,\n",
       "       -6.91609979e-02,  2.65654474e-01, -1.90774146e-02, -1.22345462e-01,\n",
       "        1.12413071e-01, -8.50751847e-02, -1.28869470e-02,  9.41280425e-02,\n",
       "        1.62221298e-01,  1.96682494e-02, -2.71834377e-02,  1.01289973e-01,\n",
       "       -8.45459551e-02,  4.58013304e-02,  4.75780219e-02, -4.67098430e-02,\n",
       "        2.04633683e-01, -1.92302078e-01, -6.98518604e-02, -4.62112799e-02,\n",
       "       -8.28603581e-02, -1.58291515e-02, -8.38419348e-02, -1.87086359e-01,\n",
       "        3.80218960e-02,  1.65422231e-01,  6.25125617e-02, -7.80872926e-02,\n",
       "       -8.46426263e-02, -2.68648565e-02, -1.43422097e-01, -5.96884266e-03,\n",
       "        2.17280630e-02, -1.59915596e-01, -5.82793467e-02,  4.97249663e-02,\n",
       "       -2.34416753e-01, -1.82620827e-02,  5.22615500e-02, -1.73194781e-02,\n",
       "       -6.77172020e-02,  1.61747545e-01,  1.68998558e-02, -9.00185257e-02,\n",
       "        1.91433392e-02,  7.44667929e-03, -1.63449392e-01, -1.53780580e-01,\n",
       "        1.94920897e-01,  5.42461164e-02, -1.94521204e-01, -3.36237177e-02,\n",
       "        1.74176842e-02,  1.28989518e-01, -3.27239573e-01,  2.24270061e-01,\n",
       "       -9.18221325e-02,  1.15003191e-01, -5.19877896e-02,  7.24157542e-02,\n",
       "       -5.06628975e-02,  1.66607141e-01,  1.08179614e-01, -4.19420078e-02,\n",
       "        6.50383756e-02,  5.52798882e-02, -2.46365026e-01, -2.39561535e-02,\n",
       "       -3.15776542e-02,  7.18766078e-02, -2.07377315e-01, -5.01382118e-03,\n",
       "       -1.82237357e-01, -8.88682380e-02,  1.17540825e-02, -6.23790994e-02,\n",
       "       -4.79981527e-02,  1.92952856e-01,  4.93068853e-03, -3.98540217e-03,\n",
       "       -5.67453317e-02,  5.54131158e-02, -9.47335921e-03, -8.74496922e-02,\n",
       "        3.64748910e-02, -1.63011536e-01,  3.32050547e-02,  2.41290182e-01,\n",
       "       -4.49455418e-02,  3.20581123e-02, -2.68455688e-02,  1.06282458e-01,\n",
       "       -2.15418130e-01, -1.10070646e-01, -7.07072467e-02, -5.92835620e-02,\n",
       "       -1.33648187e-01, -1.74195156e-01,  1.79790554e-03,  3.37063879e-01,\n",
       "       -1.75684154e-01, -1.40756937e-02,  3.19464147e-01, -5.95962293e-02,\n",
       "       -1.10607766e-01,  1.17099926e-01, -1.55887023e-01, -2.34491825e-01,\n",
       "       -8.33974704e-02,  5.56795895e-02,  1.77260444e-01,  1.30755410e-01,\n",
       "       -2.26731941e-01,  7.08622113e-02, -2.18189284e-01,  4.97308560e-02,\n",
       "       -1.75180025e-02, -6.17927825e-03,  5.14204502e-02, -1.27679080e-01,\n",
       "       -9.22084451e-02,  1.08709261e-01, -2.44332459e-02,  1.36068240e-01,\n",
       "        6.44380227e-02, -8.50772634e-02,  2.63305064e-02,  1.15569964e-01,\n",
       "       -1.57359153e-01, -9.62084979e-02,  2.00816318e-01,  5.74319670e-03,\n",
       "       -7.81346560e-02,  1.35219783e-01,  6.52321354e-02, -1.93946794e-01,\n",
       "        3.21844704e-02,  2.12519430e-03,  1.00936033e-01, -1.15258731e-01,\n",
       "        5.23639545e-02,  2.29896381e-01,  2.02069968e-01, -5.31719811e-02,\n",
       "        1.18062019e-01,  1.67604700e-01,  4.40817252e-02,  2.35461161e-01,\n",
       "       -1.37367100e-01,  8.74256045e-02,  2.34275967e-01, -5.28838411e-02,\n",
       "       -2.13443398e-01, -1.19743302e-01,  1.09508559e-01, -1.70494877e-02,\n",
       "        1.91968270e-02, -3.87329906e-02, -8.32862481e-02, -4.20482159e-02,\n",
       "        8.56145769e-02, -4.07333523e-02,  2.04125911e-01,  2.87459373e-01,\n",
       "        1.52774885e-01,  1.19033851e-01,  2.34786607e-03, -1.89460278e-01,\n",
       "        8.38687941e-02,  8.93730521e-02,  1.73717171e-01, -3.46954283e-03,\n",
       "        1.46551952e-02, -1.32915691e-01,  9.53386948e-02, -5.10182604e-02,\n",
       "       -7.32568949e-02, -1.23076200e-01, -3.06732301e-02,  1.53298661e-01,\n",
       "        7.21141845e-02, -6.15713187e-02,  4.67742011e-02, -5.73637374e-02,\n",
       "       -7.84385055e-02, -3.00509091e-02,  2.48068660e-01,  4.36289087e-02,\n",
       "        7.83055574e-02,  3.21147256e-02,  1.60087615e-01, -1.48613125e-01,\n",
       "        1.58086047e-01,  2.57976614e-02, -9.16094109e-02, -1.40495360e-01,\n",
       "        2.46157758e-02, -3.62905040e-02, -5.97845344e-03,  5.51707819e-02,\n",
       "        8.76294374e-02, -2.23173052e-02,  7.22740293e-02,  1.21353470e-01,\n",
       "       -7.48995692e-02, -1.61965936e-01, -9.47885402e-03, -3.23884748e-02,\n",
       "       -5.40573671e-02, -1.43972903e-01,  9.52630639e-02,  1.83897048e-01,\n",
       "        4.77948412e-02,  3.66822642e-04, -1.24403939e-01,  2.52011660e-02,\n",
       "        6.91948086e-02, -1.24834970e-01,  2.32365951e-02,  9.93562415e-02,\n",
       "       -3.46646607e-02,  2.47074991e-01,  1.24840021e-01, -2.18900181e-02,\n",
       "       -5.67361936e-02,  1.25601977e-01, -1.68584496e-01, -2.20976733e-02,\n",
       "       -3.05072255e-02, -1.12528943e-01,  2.79290671e-03,  9.89037007e-02,\n",
       "        3.93177941e-02,  8.56019929e-03, -2.36131512e-02, -2.69060045e-01,\n",
       "        1.29603848e-01,  2.56479770e-01,  2.01333001e-01,  1.10623814e-01,\n",
       "        1.27149239e-01,  5.76864481e-02,  3.02436594e-02,  6.04412444e-02,\n",
       "       -8.23799223e-02,  7.84488395e-03,  9.21027921e-03,  2.82185495e-01,\n",
       "       -2.34849602e-02, -2.98057258e-01,  7.74901286e-02, -2.68548071e-01,\n",
       "        3.19194719e-02,  1.07702538e-01,  6.85781986e-02,  1.97264347e-02,\n",
       "        2.26628989e-01, -5.02836779e-02, -6.83872262e-03,  2.58150343e-02,\n",
       "        2.18967229e-01,  2.93258373e-02,  1.12041965e-01,  5.70725929e-03,\n",
       "       -1.25509724e-01, -1.22040207e-03, -1.35353521e-01, -4.29289006e-02,\n",
       "        1.24802791e-01, -1.10661820e-01,  1.99953886e-03,  6.72730710e-03,\n",
       "       -4.15717453e-01, -9.62176695e-02,  1.91155836e-01,  6.36757463e-02,\n",
       "       -1.63830191e-01,  8.97150412e-02, -2.13702649e-01,  8.20244551e-02,\n",
       "       -9.39280614e-02, -2.06957310e-01, -1.46246087e-02, -1.45870313e-01,\n",
       "       -7.06379563e-02,  1.48808537e-02, -1.39098316e-01,  2.61579216e-01,\n",
       "        2.81283613e-02, -1.01204157e-01,  8.84403512e-02, -1.28608182e-01,\n",
       "       -8.06492195e-02, -5.74668497e-03,  1.03365779e-01, -3.04090092e-03,\n",
       "        5.89191914e-04,  1.44706983e-02, -5.51056750e-02,  2.06169173e-01,\n",
       "       -9.13102776e-02,  6.64491504e-02,  1.45909395e-02, -8.28477740e-02,\n",
       "        1.09747097e-01,  4.62164804e-02, -5.85519783e-02,  6.33248612e-02,\n",
       "        1.39241725e-01, -7.45497784e-03, -2.59953171e-01, -1.36806101e-01,\n",
       "       -8.65653306e-02, -6.98907441e-03, -5.79571165e-03,  3.47076356e-02,\n",
       "       -3.59760597e-02, -4.75975201e-02,  6.78851604e-02, -3.15078288e-01,\n",
       "       -4.73215058e-02, -8.44159871e-02, -2.22206414e-02, -1.62135556e-01,\n",
       "        5.67944236e-02, -9.31900740e-02, -3.49682719e-02, -6.96227700e-02,\n",
       "       -6.16241246e-03,  2.25466728e-01,  3.41676932e-04,  1.66914612e-01,\n",
       "        4.52768728e-02, -1.26470830e-02,  3.26218545e-01, -1.25729321e-02,\n",
       "       -4.16560378e-03, -3.96970063e-02, -2.15424135e-01, -6.83566406e-02,\n",
       "        1.67285398e-01,  1.26734212e-01, -1.16840519e-01, -2.24156305e-01,\n",
       "        1.61647901e-01, -1.78390101e-01,  6.45773038e-02,  8.34422335e-02,\n",
       "       -7.24460036e-02,  5.20229936e-02, -6.08504936e-02,  8.04800019e-02,\n",
       "       -1.26294822e-01, -9.75420550e-02, -2.33946085e-01,  1.54065132e-01,\n",
       "       -1.11137554e-02,  5.31675704e-02,  6.84358831e-03, -1.17536366e-01,\n",
       "        1.50681704e-01, -2.51801759e-01, -2.35219210e-01, -4.39318307e-02,\n",
       "        2.69754022e-01,  1.53407201e-01, -2.14943200e-01, -8.52899179e-02,\n",
       "       -3.60377319e-02, -7.81186894e-02,  5.84184751e-02,  9.18371603e-02,\n",
       "       -9.09520835e-02,  1.33549362e-01, -5.19317165e-02,  1.19912110e-01,\n",
       "       -1.40269279e-01,  2.15720341e-01, -7.96137899e-02,  1.80434324e-02,\n",
       "        4.02863920e-02,  1.28152937e-01,  7.89121985e-02, -1.07940055e-01,\n",
       "        1.86821356e-01, -1.65180951e-01,  1.12784550e-01, -6.47932515e-02,\n",
       "        2.34622806e-01,  6.65200949e-01,  1.16708398e-01, -2.75592562e-02,\n",
       "       -1.39564425e-01, -5.03765233e-02,  2.34632760e-01,  1.77108109e-01,\n",
       "       -5.73157780e-02,  6.71290373e-03, -7.22667426e-02,  1.07720956e-01,\n",
       "        4.26377133e-02,  9.34510231e-02,  6.51687756e-02,  4.94409874e-02,\n",
       "       -1.22826315e-01, -5.34579232e-02, -8.33789855e-02,  1.16625503e-01,\n",
       "       -2.46632267e-02, -1.37120903e-01, -4.28340323e-02,  2.17217639e-01,\n",
       "        1.68413207e-01, -3.83955911e-02,  8.86535048e-02, -1.37430117e-01,\n",
       "        2.28362873e-01, -4.40850807e-03,  1.13626897e-01, -1.42698973e-01,\n",
       "        4.11835983e-02, -9.64749604e-02, -6.37352914e-02,  8.08435231e-02,\n",
       "       -2.23223135e-01, -5.11945128e-01, -2.28639886e-01,  1.07550666e-01,\n",
       "       -2.14253455e-01, -9.79699865e-02,  3.36784944e-02,  6.31388575e-02,\n",
       "        3.47256064e-02, -5.00012562e-03, -9.72969085e-02,  1.26631349e-01,\n",
       "        5.76345399e-02, -9.44368839e-02, -1.41106965e-02,  1.77876830e-01,\n",
       "       -1.72514290e-01,  3.71055380e-02, -1.35371298e-01,  3.89517136e-02,\n",
       "        2.22890407e-01, -4.24631745e-01,  2.09832907e-01, -4.56252843e-02,\n",
       "        3.54641750e-02, -2.11168285e-02,  1.20821893e-01,  6.59787580e-02,\n",
       "       -8.64836425e-02, -7.54083991e-02, -4.09645066e-02, -1.78875133e-01,\n",
       "       -4.95237038e-02,  3.31784278e-01, -2.84406662e-01, -2.20543191e-01,\n",
       "        1.23417554e-02,  1.47434115e-01, -1.70062900e-01, -3.93328145e-02,\n",
       "       -1.15683794e-01,  2.10296623e-02, -4.10352573e-02, -2.10196942e-01,\n",
       "       -9.29911286e-02, -1.41865835e-01,  5.86398058e-02, -2.96176616e-02,\n",
       "        1.50865123e-01,  1.52890414e-01, -1.45622537e-01,  1.37013957e-01,\n",
       "        1.69519022e-01, -6.02519587e-02,  1.40204251e-01,  1.59157757e-02,\n",
       "       -3.62594634e-01, -2.83899251e-02,  6.72668144e-02, -4.08349447e-02,\n",
       "        3.69175449e-02,  1.08066574e-01, -9.24908370e-02,  1.12660810e-01,\n",
       "        2.20916659e-01, -4.71386407e-03,  1.94630679e-02,  4.79021743e-02,\n",
       "        7.67735466e-02,  8.49892721e-02, -3.09360512e-02, -8.16784278e-02,\n",
       "        8.51656776e-03,  3.88850048e-02,  3.54320626e-03, -1.13030039e-02,\n",
       "       -3.63462046e-02,  2.60177076e-01,  4.64368686e-02, -1.83199402e-02,\n",
       "       -1.74368382e-01,  4.43545869e-03, -4.78136837e-02,  3.38573828e-02,\n",
       "        5.47545683e-03,  4.95042056e-02, -8.92152078e-03, -9.76683274e-02,\n",
       "       -1.03590488e-01,  1.24883533e-01, -3.83839607e-02,  2.00104743e-01,\n",
       "       -4.58341017e-02,  9.37465206e-02,  4.40917127e-02,  3.18430997e-02,\n",
       "        3.86653990e-01,  3.30306701e-02, -1.77352399e-01, -1.85100511e-01,\n",
       "       -9.81774647e-03, -6.20324090e-02,  1.68386966e-01,  1.48720503e-01,\n",
       "       -1.33832367e-02,  2.13370174e-01,  4.66233678e-02,  1.10948280e-01,\n",
       "       -3.11515749e-01,  1.91889238e-02, -9.43113416e-02, -6.93437606e-02,\n",
       "        5.26937023e-02, -2.54618764e-01, -7.68321007e-02,  1.30044326e-01,\n",
       "        2.53990348e-02,  1.99279398e-01,  5.64670190e-03,  2.44789217e-02,\n",
       "       -7.28951097e-02, -2.50107467e-01,  2.41579171e-02, -3.60825583e-02,\n",
       "        1.10054210e-01,  5.72815770e-03, -1.17131993e-01, -6.36710525e-02,\n",
       "        2.59899087e-02,  1.74341977e-01,  1.86596625e-02,  1.03713967e-01,\n",
       "        2.45062783e-01, -1.61909014e-01, -4.78076302e-02, -1.43675711e-02,\n",
       "       -1.71915293e-02,  1.62959129e-01, -1.10044539e-01, -2.70035751e-02,\n",
       "       -2.29182169e-01, -8.14114735e-02, -1.28775924e-01, -1.11027658e-01,\n",
       "        1.74316019e-02,  2.05246493e-01,  8.53014886e-02,  4.80012186e-02,\n",
       "       -3.06866132e-02, -1.10348940e-01, -1.17436089e-01,  2.52286308e-02,\n",
       "       -8.96974578e-02, -4.35567573e-02, -7.31439888e-02, -3.14391077e-01,\n",
       "       -5.10679260e-02, -3.55425254e-02, -1.97501823e-01, -1.53587341e-01,\n",
       "       -1.02804795e-01, -6.98544309e-02, -4.02938761e-02,  1.42678708e-01,\n",
       "        9.47994441e-02,  2.64163921e-03,  5.60458601e-02, -1.44060880e-01,\n",
       "       -1.73820049e-01, -4.70551252e-02, -5.67066893e-02,  4.99687418e-02,\n",
       "       -7.55538568e-02, -3.01864464e-03,  7.31193125e-02, -5.31626754e-02,\n",
       "       -7.94280600e-03,  6.34414405e-02,  1.53152421e-01,  8.40793699e-02,\n",
       "       -9.45743769e-02, -9.71646383e-02, -1.32753756e-02, -2.00929239e-01,\n",
       "        8.40721130e-02,  9.49648470e-02,  9.01160315e-02, -3.93991843e-02,\n",
       "       -3.00612956e-01, -2.17553288e-01,  1.44300458e-03, -1.61546201e-01,\n",
       "        8.67327824e-02, -5.74967042e-02,  7.67198950e-02,  1.03221431e-01,\n",
       "        1.53108835e-01,  3.89478877e-02,  1.06453672e-01,  5.89243658e-02,\n",
       "        5.44453487e-02, -3.20606604e-02, -3.17337871e-01,  4.28261980e-02,\n",
       "       -4.08072993e-02, -7.94251338e-02,  3.73013556e-01, -2.52642810e-01,\n",
       "        1.86119244e-01, -1.97485775e-01,  2.82956474e-02, -5.96106164e-02,\n",
       "       -9.10209119e-02,  1.27474278e-01, -1.45818572e-02,  4.15868275e-02,\n",
       "       -5.64175434e-02,  4.94478978e-02,  4.82310988e-02, -1.09557785e-01,\n",
       "       -1.53327376e-01,  6.34924099e-02, -4.75093052e-02, -2.05704883e-01,\n",
       "        1.32002681e-01, -7.43875727e-02, -4.23775278e-02,  1.18974773e-02,\n",
       "        6.80563077e-02, -4.36447151e-02, -4.36927900e-02, -4.54500876e-02,\n",
       "        1.79783866e-01,  5.79705946e-02,  5.75173870e-02,  6.65712729e-02,\n",
       "        6.20120354e-02,  1.27975360e-01,  6.20930083e-02,  4.08081710e-02,\n",
       "        2.05347568e-01,  1.59526244e-01,  6.55016452e-02,  8.34278241e-02,\n",
       "       -1.05196871e-01,  1.89640671e-01,  1.38763279e-01,  9.58150774e-02,\n",
       "       -3.74795683e-02,  1.61355257e-01,  1.05714843e-01, -1.46287724e-01,\n",
       "       -6.37997165e-02, -3.59080136e-02,  1.26005620e-01,  3.64828221e-02,\n",
       "        1.33744419e-01,  5.65991774e-02,  7.26696700e-02, -1.01960264e-01,\n",
       "       -1.67260438e-01, -1.80588752e-01,  1.91640444e-02,  6.11853786e-02,\n",
       "        1.21914864e-01,  1.26483336e-01,  3.44513245e-02,  2.52465010e-01,\n",
       "        2.36565191e-02,  1.58284735e-02,  1.26289278e-02, -1.76671639e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_encodings = st_model.encode(\"I love apple\")\n",
    "print(setfit_encodings.shape)\n",
    "st_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can confirm that the same embeddings can be produced from both pretrained models\n",
    "# as they are essentially the same thing but retrieved differently\n",
    "setfit_encodings == st_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78f7c6b3bc634eefacb770fdcdcc3cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)f333f/.gitattributes:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af664d1c6ae644b2b7c0d584e85451d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b39ba10b24bb4021bbc3daa977900ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)4d423f333f/README.md:   0%|          | 0.00/4.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e8341b3f477467ab35e6c31ae16bd10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)423f333f/config.json:   0%|          | 0.00/827 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d64e271f99408086f6e4bd972b5cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7704839a57534eee86ca13ec6e54487b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/46.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f43f50b102d74dd0a1a605f24983a776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89587f1e4e594d9f84ed46654907a906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/245 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c783084005043bfa46e0d112d583625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b3e24c2c134a4c82b741b63bfb1066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)f333f/tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "770d189e0f2e42bb9ceb3ca468efd8bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/465 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43bf41c74bb3467fa6c61d22c39a7b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)23f333f/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we can test with another small ST model which was finetuned on different dataset(s)\n",
    "# note that different pretrained models produce different dimensions of embeddings, choose one that is comparable (e.g., 768 here)\n",
    "# refer to Sentence Transformer website / Pretrained Models\n",
    "st_model_2 = SentenceTransformer('sentence-transformers/paraphrase-albert-small-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as it is trained on a different dataset, the embeddings produced will not be the same as the previous model\n",
    "st_encodings_2 = st_model_2.encode(\"I love apple\")\n",
    "print(st_encodings_2.shape)\n",
    "st_encodings_2 == st_encodings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "286bc12fa30b74ef856228bed3e3c37bde5be697e37af5195e71bc249a2a5043"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
