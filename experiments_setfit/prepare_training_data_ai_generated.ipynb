{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from datasets import Dataset, DatasetDict\n",
    "from datasets import ClassLabel\n",
    "import pandas as pd\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "import numpy as np\n",
    "from setfit import SetFitModel, SetFitTrainer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_leading_numbering(input_string, delimiter=\". \"):\n",
    "    return input_string.split(delimiter, 1)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3020ca23484302b832b8b8e33d4742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login, logout\n",
    "login()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Creating custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_folder = '../temp_training/ai_generated_para'\n",
    "file_names = os.listdir(parent_folder)\n",
    "dataset_dict = {\"class_name\": [],\n",
    "                \"class_name_for_onehot\":[],\n",
    "                \"text\": []}\n",
    "for file_name in file_names:\n",
    "    match = re.match(r'^(\\d+)_(\\w+)', file_name)\n",
    "    # class_index = int(match.group(1))\n",
    "    class_name = match.group(2)\n",
    "    file_path = os.path.join(parent_folder, file_name)\n",
    "    sentences = []  # Initialize an empty list to store the lines\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Check if the line contains alphabetical characters and doesn't start with a number\n",
    "            if any(c.isalpha() for c in line):\n",
    "                sentences.append(remove_leading_numbering(line.strip()))\n",
    "    # class_indices = [class_index]*len(sentences)\n",
    "    class_names = [class_name]*len(sentences)\n",
    "    # dataset_dict['class_index'].extend(class_indices)\n",
    "    dataset_dict['class_name'].extend(class_names)\n",
    "    dataset_dict['class_name_for_onehot'].extend(class_names)\n",
    "    dataset_dict['text'].extend(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# though the 'class_index' col will not be used as label cols, we still cast it to label feature to stratify the dataset during train/test split\n",
    "# non_labels = ['text', 'class_name']\n",
    "dataset_df = pd.DataFrame(dataset_dict)\n",
    "encoded_df = pd.get_dummies(dataset_df, columns = ['class_name_for_onehot'], prefix=\"\", prefix_sep='', dtype=int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure labels and their indices from the table:\n",
    "non_label_columns = ['text', 'class_name']\n",
    "label_columns = [column for column in encoded_df.columns if column not in non_label_columns]\n",
    "label_indices = range(len(label_columns))\n",
    "label_dict = {k:v for (k,v) in zip(label_columns, label_indices)}\n",
    "encoded_df['class_index'] = encoded_df.apply(lambda row: (label_dict[row['class_name']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_name</th>\n",
       "      <th>text</th>\n",
       "      <th>aviation</th>\n",
       "      <th>cybersecurity</th>\n",
       "      <th>domestic_unrest_violence</th>\n",
       "      <th>extreme_weather</th>\n",
       "      <th>forced_labor</th>\n",
       "      <th>general_biz_trend</th>\n",
       "      <th>individual_accidents_tragedies</th>\n",
       "      <th>later_report</th>\n",
       "      <th>...</th>\n",
       "      <th>leisure_other_news</th>\n",
       "      <th>maritime</th>\n",
       "      <th>pandemics_large_scale_diseases</th>\n",
       "      <th>railway</th>\n",
       "      <th>strike</th>\n",
       "      <th>trade_war_embargos_bans</th>\n",
       "      <th>transportation_trends_projects</th>\n",
       "      <th>war_conflict</th>\n",
       "      <th>warehouse_fire</th>\n",
       "      <th>class_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lawsuit_legal_insurance</td>\n",
       "      <td>In the aftermath of the catastrophic fire that...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lawsuit_legal_insurance</td>\n",
       "      <td>Residents of Phoenix are up in arms following ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lawsuit_legal_insurance</td>\n",
       "      <td>Denver's public transportation system faces le...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lawsuit_legal_insurance</td>\n",
       "      <td>Houston's skyline was marred by chaos on Novem...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lawsuit_legal_insurance</td>\n",
       "      <td>The serene coastal town of Wilmington is rattl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                class_name                                               text  \\\n",
       "0  lawsuit_legal_insurance  In the aftermath of the catastrophic fire that...   \n",
       "1  lawsuit_legal_insurance  Residents of Phoenix are up in arms following ...   \n",
       "2  lawsuit_legal_insurance  Denver's public transportation system faces le...   \n",
       "3  lawsuit_legal_insurance  Houston's skyline was marred by chaos on Novem...   \n",
       "4  lawsuit_legal_insurance  The serene coastal town of Wilmington is rattl...   \n",
       "\n",
       "   aviation  cybersecurity  domestic_unrest_violence  extreme_weather  \\\n",
       "0         0              0                         0                0   \n",
       "1         0              0                         0                0   \n",
       "2         0              0                         0                0   \n",
       "3         0              0                         0                0   \n",
       "4         0              0                         0                0   \n",
       "\n",
       "   forced_labor  general_biz_trend  individual_accidents_tragedies  \\\n",
       "0             0                  0                               0   \n",
       "1             0                  0                               0   \n",
       "2             0                  0                               0   \n",
       "3             0                  0                               0   \n",
       "4             0                  0                               0   \n",
       "\n",
       "   later_report  ...  leisure_other_news  maritime  \\\n",
       "0             0  ...                   0         0   \n",
       "1             0  ...                   0         0   \n",
       "2             0  ...                   0         0   \n",
       "3             0  ...                   0         0   \n",
       "4             0  ...                   0         0   \n",
       "\n",
       "   pandemics_large_scale_diseases  railway  strike  trade_war_embargos_bans  \\\n",
       "0                               0        0       0                        0   \n",
       "1                               0        0       0                        0   \n",
       "2                               0        0       0                        0   \n",
       "3                               0        0       0                        0   \n",
       "4                               0        0       0                        0   \n",
       "\n",
       "   transportation_trends_projects  war_conflict  warehouse_fire  class_index  \n",
       "0                               0             0               0            8  \n",
       "1                               0             0               0            8  \n",
       "2                               0             0               0            8  \n",
       "3                               0             0               0            8  \n",
       "4                               0             0               0            8  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dataset_dict = encoded_df.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e49ad0e84144d2dafbb7c70064f8db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = Dataset.from_dict(result_dataset_dict)\n",
    "label_features = [feature for feature in dataset.features if feature not in non_label_columns]\n",
    "new_features = dataset.features.copy()\n",
    "for label_feature in label_features:\n",
    "    new_features[label_feature] = ClassLabel(num_classes=2) # binary for each one-hot\n",
    "dataset = dataset.cast(new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using train_test_split method creates a DatasetDict, \n",
    "# shuffle is enabled by default\n",
    "# this step is done twice to create 3 datasets - train, valid, test\n",
    "train_validtest = dataset.train_test_split(test_size=0.2, seed=99, stratify_by_column=\"class_index\")\n",
    "valid_test = train_validtest['test'].train_test_split(test_size=0.5, seed=99, stratify_by_column=\"class_index\")\n",
    "train_valid_test_dataset = DatasetDict({\n",
    "    'train': train_validtest['train'],\n",
    "    'valid': valid_test['train'],\n",
    "    'test': valid_test['test']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2: 40, 0: 40, 13: 40, 6: 40, 9: 40, 3: 40, 16: 40, 12: 40, 1: 40, 7: 40, 14: 40, 10: 40, 11: 40, 8: 40, 17: 40, 15: 40, 5: 40, 4: 40})\n",
      "==============================\n",
      "Counter({1: 5, 5: 5, 14: 5, 3: 5, 0: 5, 15: 5, 12: 5, 11: 5, 16: 5, 6: 5, 4: 5, 9: 5, 10: 5, 8: 5, 7: 5, 17: 5, 2: 5, 13: 5})\n",
      "==============================\n",
      "Counter({13: 5, 4: 5, 15: 5, 2: 5, 5: 5, 11: 5, 9: 5, 6: 5, 10: 5, 3: 5, 14: 5, 0: 5, 8: 5, 7: 5, 1: 5, 16: 5, 12: 5, 17: 5})\n",
      "==============================\n",
      "Counter({'domestic_unrest_violence': 40, 'aviation': 40, 'strike': 40, 'individual_accidents_tragedies': 40, 'leisure_other_news': 40, 'extreme_weather': 40, 'war_conflict': 40, 'railway': 40, 'cybersecurity': 40, 'later_report': 40, 'trade_war_embargos_bans': 40, 'maritime': 40, 'pandemics_large_scale_diseases': 40, 'lawsuit_legal_insurance': 40, 'warehouse_fire': 40, 'transportation_trends_projects': 40, 'general_biz_trend': 40, 'forced_labor': 40})\n",
      "==============================\n",
      "Counter({'cybersecurity': 5, 'general_biz_trend': 5, 'trade_war_embargos_bans': 5, 'extreme_weather': 5, 'aviation': 5, 'transportation_trends_projects': 5, 'railway': 5, 'pandemics_large_scale_diseases': 5, 'war_conflict': 5, 'individual_accidents_tragedies': 5, 'forced_labor': 5, 'leisure_other_news': 5, 'maritime': 5, 'lawsuit_legal_insurance': 5, 'later_report': 5, 'warehouse_fire': 5, 'domestic_unrest_violence': 5, 'strike': 5})\n",
      "==============================\n",
      "Counter({'strike': 5, 'forced_labor': 5, 'transportation_trends_projects': 5, 'domestic_unrest_violence': 5, 'general_biz_trend': 5, 'pandemics_large_scale_diseases': 5, 'leisure_other_news': 5, 'individual_accidents_tragedies': 5, 'maritime': 5, 'extreme_weather': 5, 'trade_war_embargos_bans': 5, 'aviation': 5, 'lawsuit_legal_insurance': 5, 'later_report': 5, 'cybersecurity': 5, 'war_conflict': 5, 'railway': 5, 'warehouse_fire': 5})\n"
     ]
    }
   ],
   "source": [
    "# we can verify that the stratification is done\n",
    "import collections\n",
    "counter_train = collections.Counter(train_valid_test_dataset['train']['class_index'])\n",
    "counter_valid = collections.Counter(train_valid_test_dataset['valid']['class_index'])\n",
    "counter_test = collections.Counter(train_valid_test_dataset['test']['class_index'])\n",
    "\n",
    "print(counter_train)\n",
    "print(\"=\"*30)\n",
    "print(counter_valid)\n",
    "print(\"=\"*30)\n",
    "print(counter_test)\n",
    "print(\"=\"*30)\n",
    "# if seeing by class name:\n",
    "counter_train = collections.Counter(train_valid_test_dataset['train']['class_name'])\n",
    "counter_valid = collections.Counter(train_valid_test_dataset['valid']['class_name'])\n",
    "counter_test = collections.Counter(train_valid_test_dataset['test']['class_name'])\n",
    "\n",
    "print(counter_train)\n",
    "print(\"=\"*30)\n",
    "print(counter_valid)\n",
    "print(\"=\"*30)\n",
    "print(counter_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd5e496453284b5b9b420d9d153c4122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/720 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7e8a2f0bb04c86a33d00eaff2e8d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/90 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1db66e109029408e9ea6cbdb2536ac3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/90 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare a list of all labels\n",
    "labels = [col_name for col_name in train_valid_test_dataset['train'].column_names\\\n",
    "                   if col_name not in ['text', 'class_index', 'class_name']]\n",
    "\n",
    "# helper function to extract the one-hot array value of each row:\n",
    "def encode_labels(record):\n",
    "    return {\"label\": [record[feature] for feature in labels]}\n",
    "\n",
    "train_valid_test_dataset = train_valid_test_dataset.map(encode_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_name': 'domestic_unrest_violence',\n",
       " 'text': 'Buenos Aires, Argentina, grappled with civic unrest as citizens protested against economic austerity measures. The demonstrations, marked by clashes with security forces, exposed the deepening economic challenges facing the South American nation.',\n",
       " 'aviation': 0,\n",
       " 'cybersecurity': 0,\n",
       " 'domestic_unrest_violence': 1,\n",
       " 'extreme_weather': 0,\n",
       " 'forced_labor': 0,\n",
       " 'general_biz_trend': 0,\n",
       " 'individual_accidents_tragedies': 0,\n",
       " 'later_report': 0,\n",
       " 'lawsuit_legal_insurance': 0,\n",
       " 'leisure_other_news': 0,\n",
       " 'maritime': 0,\n",
       " 'pandemics_large_scale_diseases': 0,\n",
       " 'railway': 0,\n",
       " 'strike': 0,\n",
       " 'trade_war_embargos_bans': 0,\n",
       " 'transportation_trends_projects': 0,\n",
       " 'war_conflict': 0,\n",
       " 'warehouse_fire': 0,\n",
       " 'class_index': 2,\n",
       " 'label': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random verification to check the agreement of class_name, one-hot value, class_index, label\n",
    "train_valid_test_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9148da4b13ee43278367ab12cddf4147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c3b389decf4e08940fab1ec83f3a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe6be477ef4446138287b49890c65c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164585ae136f442682749b97417a1bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9d0aa22b4b4712bca6ddb9922ac1e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e01f7c7503f54e95bfdd641e277127da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pushing to hub:\n",
    "# train_valid_test_dataset.push_to_hub(\"joshuapsa/gpt-generated-news-paragraphs-v1.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can save and reload the dataset by:\n",
    "# dataset.save_to_disk('./custom_datasets/sample_dataset')\n",
    "# from datasets import load_from_disk\n",
    "# reloaded_dataset = load_from_disk(\"./custom_datasets/sample_dataset\")\n",
    "# reloaded_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Multi-label text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# getting pretrained model from Huggingface and save it\n",
    "# model_id = \"sentence-transformers/paraphrase-mpnet-base-v2\"\n",
    "# model = SetFitModel.from_pretrained(model_id, # use any Sentence transformer model\n",
    "#                                     multi_target_strategy=\"one-vs-rest\" \n",
    "#                                     )\n",
    "# model.save_pretrained('../models/pretrained/paraphrase-mpnet-base-v2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# re-load the model from saved location\n",
    "loaded_model = SetFitModel.from_pretrained('../models/pretrained/paraphrase-mpnet-base-v2/', # use any Sentence transformer model\n",
    "                                    multi_target_strategy=\"one-vs-rest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the parameters for the finetuning process:\n",
    "# 'accuracy' is the default metric, explicitly stated for better clarity\n",
    "trainer = SetFitTrainer(\n",
    "    model=loaded_model,\n",
    "    train_dataset=train_valid_test_dataset['train'],\n",
    "    eval_dataset=train_valid_test_dataset['valid'],\n",
    "    loss_class=CosineSimilarityLoss,\n",
    "    num_iterations=5,\n",
    "    column_mapping={\"text\": \"text\", \"labels\": \"label\"}, # IMPORTANT for SetFit - hardcoded in the source code\n",
    "    num_epochs=1,\n",
    "    batch_size=5,\n",
    "    metric='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying column mapping to training dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f8d3e3e06f4adc99e37c873b708071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Training Pairs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 6400\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 1280\n",
      "  Total train batch size = 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5470f462aea347ec838ae5125fca9fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76fcfd369647474882375e7e6da21d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training (75min for 2000 summaries):\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can save the finetuned model:\n",
    "# loaded_model.save_pretrained('../models/finetuned/paraphrase-mpnet-base-v2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying column mapping to evaluation dataset\n",
      "***** Running evaluation *****\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9875}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get performance on eval dataset\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "finetuned_model = SetFitModel.from_pretrained('../models/finetuned/paraphrase-mpnet-base-v2/')\n",
    "pretrained_model = SetFitModel.from_pretrained('../models/pretrained/paraphrase-mpnet-base-v2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneVsRestClassifier(estimator=LogisticRegression())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneVsRestClassifier</label><div class=\"sk-toggleable__content\"><pre>OneVsRestClassifier(estimator=LogisticRegression())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression())"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_model.model_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on test set:\n",
    "# preds = finetuned_model.predict(train_valid_test_dataset['test']['text'])\n",
    "sample_text = 'violence broke out on the streets of Paris yesterday when demonstrators clashed with the city police'\n",
    "finetuned_pred = finetuned_model.predict([sample_text]) # ok, as the head is fitted\n",
    "# pretrained_pred = pretrained_model.predict([sample_text]) # NotFittedError: This OneVsRestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post-processing:\n",
    "texts = [text for text in train_valid_test_dataset['test']['text']]\n",
    "true_labels = [label_features[int(np.array(label).argmax())] for label in train_valid_test_dataset['test']['labels']]\n",
    "pred_labels = [label_features[int(pred.argmax())] for pred in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame({\"texts\":texts, \n",
    "                          'true_labels': true_labels,\n",
    "                          'pred_labels': pred_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df.to_csv('sample_setfit_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>INSERT_DATETIME</th>\n",
       "      <th>URI</th>\n",
       "      <th>TOPIC</th>\n",
       "      <th>TOPIC_URI</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>BODY</th>\n",
       "      <th>URL</th>\n",
       "      <th>RELEVANCE_CLASS</th>\n",
       "      <th>BODY_SUMMARY</th>\n",
       "      <th>EVENTURI</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>METADATA</th>\n",
       "      <th>ARTICLE_HIERARCHY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>09:07.6</td>\n",
       "      <td>7501230662</td>\n",
       "      <td>warehouse_fire</td>\n",
       "      <td>eb7688e0-0c9f-4e9a-a2b8-2ba000a8f11b</td>\n",
       "      <td>Fire destroys Sangre Grande block factory, house</td>\n",
       "      <td>Fire officers were up to late yesterday trying...</td>\n",
       "      <td>https://www.cnc3.co.tt/fire-destroys-sangre-gr...</td>\n",
       "      <td>1</td>\n",
       "      <td>Fire destroyed a block factory in Sangre Grand...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>02:53.0</td>\n",
       "      <td>7463581898</td>\n",
       "      <td>marine</td>\n",
       "      <td>d4dfd2e7-86fc-4098-975e-32dcf4eea142</td>\n",
       "      <td>Another rail strike in Germany to add to Europ...</td>\n",
       "      <td>A rail strike in Germany on Monday is expected...</td>\n",
       "      <td>https://theloadstar.com/another-rail-strike-in...</td>\n",
       "      <td>1</td>\n",
       "      <td>Rail strike in Germany expected to cause delay...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 INSERT_DATETIME         URI           TOPIC  \\\n",
       "0           0         09:07.6  7501230662  warehouse_fire   \n",
       "1           1         02:53.0  7463581898          marine   \n",
       "\n",
       "                              TOPIC_URI  \\\n",
       "0  eb7688e0-0c9f-4e9a-a2b8-2ba000a8f11b   \n",
       "1  d4dfd2e7-86fc-4098-975e-32dcf4eea142   \n",
       "\n",
       "                                               TITLE  \\\n",
       "0   Fire destroys Sangre Grande block factory, house   \n",
       "1  Another rail strike in Germany to add to Europ...   \n",
       "\n",
       "                                                BODY  \\\n",
       "0  Fire officers were up to late yesterday trying...   \n",
       "1  A rail strike in Germany on Monday is expected...   \n",
       "\n",
       "                                                 URL  RELEVANCE_CLASS  \\\n",
       "0  https://www.cnc3.co.tt/fire-destroys-sangre-gr...                1   \n",
       "1  https://theloadstar.com/another-rail-strike-in...                1   \n",
       "\n",
       "                                        BODY_SUMMARY EVENTURI SOURCE METADATA  \\\n",
       "0  Fire destroyed a block factory in Sangre Grand...      NaN    NaN      NaN   \n",
       "1  Rail strike in Germany expected to cause delay...      NaN    NaN      NaN   \n",
       "\n",
       "  ARTICLE_HIERARCHY  \n",
       "0               NaN  \n",
       "1               NaN  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_df = pd.read_csv('../temp_training/medallion/gold/gold_COMBINED_sentences_body_summary.csv')\n",
    "test_df = pd.read_excel('../temp_training/medallion/gold/gold_COMBINED.xlsx')\n",
    "# test_df = test_df.sample(200)\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_2 = loaded_model.predict(test_df['BODY_SUMMARY'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post-processing:\n",
    "texts_2 = [text for text in test_df['BODY_SUMMARY'].to_list()]\n",
    "pred_labels_2 = [label_features[int(pred.argmax())] for pred in preds_2]\n",
    "result_df_2 = pd.DataFrame({\"texts\":texts_2, \n",
    "                          'pred_labels': pred_labels_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_2.to_csv('sample_setfit_actual_data_body_summary_all.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "286bc12fa30b74ef856228bed3e3c37bde5be697e37af5195e71bc249a2a5043"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
