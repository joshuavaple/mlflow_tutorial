{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Softmax\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "compute_softmax = Softmax(dim=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_output <br>\n",
    "{'class_description_1': score_1, 'class_description_2': score_2} <br>\n",
    "It is important to keep the raw score, such as cosine sim, without softmax all the scores, so that we know the extent of distance between vectors, thereby the degree of \"clear cut\" prediction or \"borderline\" prediction can be analyzed. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('lawsuits or insurance news',\n",
       " tensor([[0.1381, 0.2609, 0.0382]]),\n",
       " tensor([[0.3294, 0.3725, 0.2981]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Two lists of sentences\n",
    "events = ['A train accident occured yesterday',\n",
    "             'Many people like to travel by train',\n",
    "             'Minister John Doe is facing legal proceedings']\n",
    "\n",
    "topics = ['traffic accident or disruption',\n",
    "              'lawsuits or insurance news',\n",
    "              'leisure news or other news']\n",
    "\n",
    "# for event in events:\n",
    "#     event_emb = model.encode(event, convert_to_tensor=True)\n",
    "#     for topic in topics:\n",
    "#         topic_emb = model.encode(topic, convert_to_tensor=True)\n",
    "#         cosine_score = util.cos_sim(event_emb, topic_emb)\n",
    "#         print(event)\n",
    "#         print(topic)\n",
    "#         print(cosine_score)\n",
    "#         print()\n",
    "\n",
    "def compute_similar_topics(input_text:str, topics:list):\n",
    "    topic_embs = model.encode(topics)\n",
    "    text_emb = model.encode([input_text])\n",
    "    cosine_scores = util.cos_sim(text_emb, topic_embs)\n",
    "    cosine_scores_softmax = compute_softmax(cosine_scores)\n",
    "    most_similar_topic = topics[cosine_scores.argmax()]\n",
    "    return most_similar_topic, cosine_scores, cosine_scores_softmax\n",
    "\n",
    "compute_similar_topics(events[-1], topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: A train accident occured yesterday\n",
      "Sentence 2: road traffic accident or disruption\n",
      "Cosine Similarity: 0.5312840342521667\n",
      "\n",
      "Sentence 1: Many people like to travel by train\n",
      "Sentence 2: road traffic accident or disruption\n",
      "Cosine Similarity: 0.18593277037143707\n",
      "\n",
      "Sentence 1: Many people like to travel by train\n",
      "Sentence 2: maritime traffic accident or disruption\n",
      "Cosine Similarity: 0.24450285732746124\n",
      "\n",
      "Sentence 1: dozens got hurt but noone is killed in a road accident\n",
      "Sentence 2: road traffic accident or disruption\n",
      "Cosine Similarity: 0.5538912415504456\n",
      "\n",
      "Sentence 1: dozens got hurt but noone is killed in a road accident\n",
      "Sentence 2: maritime traffic accident or disruption\n",
      "Cosine Similarity: 0.389691025018692\n",
      "\n",
      "Sentence 1: dozens got hurt but noone is killed in a road accident\n",
      "Sentence 2: air traffic accident or disruption\n",
      "Cosine Similarity: 0.437001496553421\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Assuming you have the embeddings and sentences as provided in your question\n",
    "# embeddings1 and embeddings2\n",
    "\n",
    "# Initialize an empty matrix to store cosine similarity scores\n",
    "cosine_matrix = np.zeros((len(sentences1), len(sentences2)))\n",
    "\n",
    "# Calculate cosine similarities and fill the matrix\n",
    "for i in range(len(sentences1)):\n",
    "    for j in range(len(sentences2)):\n",
    "        # Calculate cosine similarity between sentence i from list 1 and sentence j from list 2\n",
    "        cosine_score = util.cos_sim(embeddings1[i], embeddings2[j])\n",
    "        cosine_matrix[i, j] = cosine_score\n",
    "\n",
    "# Extract the lower triangular part of the matrix (including the diagonal)\n",
    "lower_triangular = np.tril(cosine_matrix)\n",
    "\n",
    "# Find the indices of non-zero elements in the lower triangular part\n",
    "row_indices, col_indices = np.where(lower_triangular > 0)\n",
    "\n",
    "# Extract the respective elements in the two text lists\n",
    "similar_sentences1 = [sentences1[i] for i in row_indices]\n",
    "similar_sentences2 = [sentences2[j] for j in col_indices]\n",
    "\n",
    "# Print the similar sentences and their cosine similarity values\n",
    "for i, j in zip(row_indices, col_indices):\n",
    "    print(\"Sentence 1:\", sentences1[i])\n",
    "    print(\"Sentence 2:\", sentences2[j])\n",
    "    print(\"Cosine Similarity:\", cosine_matrix[i, j])\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55056399, 0.55056399, 0.55056405],\n",
       "       [0.19907561, 0.19907561, 0.19907562],\n",
       "       [0.5540725 , 0.5540725 , 0.5540725 ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "286bc12fa30b74ef856228bed3e3c37bde5be697e37af5195e71bc249a2a5043"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
