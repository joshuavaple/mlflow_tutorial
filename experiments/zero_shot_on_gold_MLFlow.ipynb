{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "tqdm.pandas()\n",
    "import datetime\n",
    "from src.helpers import zero_shot_predict_single_model, get_top_n_label_and_score, save_dataframe_with_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='file:///c:/Users/JOSHUALE/Documents/Github/mlflow_tutorial/experiments/mlruns/227815192018524595', creation_time=1697818753176, experiment_id='227815192018524595', last_update_time=1697818753176, lifecycle_stage='active', name='zero_shot_prediction_L14D_001', tags={}>,\n",
       " <Experiment: artifact_location='file:///c:/Users/JOSHUALE/Documents/Github/mlflow_tutorial/experiments/mlruns/677968303451148623', creation_time=1697816832103, experiment_id='677968303451148623', last_update_time=1697816832103, lifecycle_stage='active', name='zero_shot_prediction_001', tags={}>,\n",
       " <Experiment: artifact_location='file:///c:/Users/JOSHUALE/Documents/Github/mlflow_tutorial/experiments/mlruns/0', creation_time=1697816832085, experiment_id='0', last_update_time=1697816832085, lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENT_NAME = \"zero_shot_prediction\"\n",
    "# EXPERIMENT_ID = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "mlflow.search_experiments()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For sample experiment on small df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started run: cdb489738fe74707b16ee5f81f00aa7a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a001d16732f543fa92fd5ada60bddae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for sample experiment:\n",
    "EXPERIMENT_ID = '677968303451148623'\n",
    "RUN_DESCRIPTION = ''\n",
    "with mlflow.start_run(experiment_id=EXPERIMENT_ID, description=RUN_DESCRIPTION) as run:\n",
    "    RUN_ID = run.info.run_id\n",
    "    print(f\"Started run: {RUN_ID}\")\n",
    "    # change path accordingly\n",
    "    class_labels_data_path = '../data/input/class_label_by_topic.csv'\n",
    "    class_labels_data = pd.read_csv(class_labels_data_path)\n",
    "    candidate_labels = list(class_labels_data['CLASS_DESCRIPTION'])\n",
    "\n",
    "    inference_input_data_path = '../temp_training/medallion/gold_NEWS_API_ML_LABELLED_summary.csv'\n",
    "    inference_df = pd.read_csv(inference_input_data_path)\n",
    "    inference_df = inference_df.sample(5, random_state=99) # getting a sample only\n",
    "\n",
    "    model_path = '../models/pretrained/bart-large-mnli/'\n",
    "    loaded_classifier = pipeline(\"zero-shot-classification\", model=model_path)\n",
    "    \n",
    "    mlflow.log_param(\"model_path\", model_path)\n",
    "    mlflow.log_artifact(class_labels_data_path, \"class_labels_data\")\n",
    "    mlflow.log_artifact(inference_input_data_path, \"inference_input_data\")\n",
    "    \n",
    "    inference_df['ZERO_SHOT_PREDICTION'] = inference_df.progress_apply(lambda row: \n",
    "                                                   zero_shot_predict_single_model(\n",
    "                                                       classifier=loaded_classifier, \n",
    "                                                       sequence_to_classify=row['BODY_SUMMARY'], \n",
    "                                                       candidate_labels=candidate_labels), \n",
    "                                                    axis=1)\n",
    "    inference_df['FIRST_PREDICTION_CLASS'] = inference_df['ZERO_SHOT_PREDICTION'].apply(lambda result_dict: get_top_n_label_and_score(result_dict, 1)[0])\n",
    "    inference_df['FIRST_PREDICTION_SCORE'] = inference_df['ZERO_SHOT_PREDICTION'].apply(lambda result_dict: get_top_n_label_and_score(result_dict, 1)[1])\n",
    "    inference_df['SECOND_PREDICTION_CLASS'] = inference_df['ZERO_SHOT_PREDICTION'].apply(lambda result_dict: get_top_n_label_and_score(result_dict, 2)[0])\n",
    "    inference_df['SECOND_PREDICTION_SCORE'] = inference_df['ZERO_SHOT_PREDICTION'].apply(lambda result_dict: get_top_n_label_and_score(result_dict, 2)[1])\n",
    "    # Save the DataFrame to a CSV file\n",
    "    current_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    predictions_path = f\"./output/temp_mlflow/zero_shot_prediction_{current_datetime}.csv\"\n",
    "    inference_df.to_csv(predictions_path, index=False)\n",
    "    # Log the CSV file as an artifact\n",
    "    mlflow.log_artifact(predictions_path, f\"zero_shot_prediction\")\n",
    "mlflow.end_run() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For prediction on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started run: 647dfdc244ad4e1eacbdb89518721ffd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8bd045ade794a44b2a4a140d71c7f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for time consuming experiment:\n",
    "EXPERIMENT_ID = '227815192018524595'\n",
    "RUN_DESCRIPTION = ''\n",
    "with mlflow.start_run(experiment_id=EXPERIMENT_ID, description=RUN_DESCRIPTION) as run:\n",
    "    RUN_ID = run.info.run_id\n",
    "    print(f\"Started run: {RUN_ID}\")\n",
    "    # change path accordingly\n",
    "    class_labels_data_path = '../data/input/class_label_by_topic.csv'\n",
    "    class_labels_data = pd.read_csv(class_labels_data_path)\n",
    "    candidate_labels = list(class_labels_data['CLASS_DESCRIPTION'])\n",
    "\n",
    "    inference_input_data_path = '../temp_training/medallion/gold_NEWS_API_ML_LABELLED_summary.csv'\n",
    "    inference_df = pd.read_csv(inference_input_data_path)\n",
    "    # inference_df = inference_df.sample(5, random_state=99) # getting a sample only\n",
    "\n",
    "    model_path = '../models/pretrained/bart-large-mnli/'\n",
    "    loaded_classifier = pipeline(\"zero-shot-classification\", model=model_path)\n",
    "    \n",
    "    mlflow.log_param(\"model_path\", model_path)\n",
    "    mlflow.log_artifact(class_labels_data_path, \"class_labels_data\")\n",
    "    mlflow.log_artifact(inference_input_data_path, \"inference_input_data\")\n",
    "    \n",
    "    inference_df['ZERO_SHOT_PREDICTION'] = inference_df.progress_apply(lambda row: \n",
    "                                                   zero_shot_predict_single_model(\n",
    "                                                       classifier=loaded_classifier, \n",
    "                                                       sequence_to_classify=row['BODY_SUMMARY'], \n",
    "                                                       candidate_labels=candidate_labels), \n",
    "                                                    axis=1)\n",
    "    inference_df['FIRST_PREDICTION_CLASS'] = inference_df['ZERO_SHOT_PREDICTION'].apply(lambda result_dict: get_top_n_label_and_score(result_dict, 1)[0])\n",
    "    inference_df['FIRST_PREDICTION_SCORE'] = inference_df['ZERO_SHOT_PREDICTION'].apply(lambda result_dict: get_top_n_label_and_score(result_dict, 1)[1])\n",
    "    inference_df['SECOND_PREDICTION_CLASS'] = inference_df['ZERO_SHOT_PREDICTION'].apply(lambda result_dict: get_top_n_label_and_score(result_dict, 2)[0])\n",
    "    inference_df['SECOND_PREDICTION_SCORE'] = inference_df['ZERO_SHOT_PREDICTION'].apply(lambda result_dict: get_top_n_label_and_score(result_dict, 2)[1])\n",
    "    # Save the DataFrame to a CSV file\n",
    "    current_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    predictions_path = f\"./output/temp_mlflow/zero_shot_prediction_{current_datetime}.csv\"\n",
    "    inference_df.to_csv(predictions_path, index=False)\n",
    "    # Log the CSV file as an artifact\n",
    "    mlflow.log_artifact(predictions_path, f\"zero_shot_prediction\")\n",
    "mlflow.end_run() \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "286bc12fa30b74ef856228bed3e3c37bde5be697e37af5195e71bc249a2a5043"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
