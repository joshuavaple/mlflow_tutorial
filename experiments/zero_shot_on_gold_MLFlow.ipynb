{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported src\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "tqdm.pandas()\n",
    "import datetime\n",
    "from src.helpers import zero_shot_predict_single_model, get_top_n_label_and_score, save_dataframe_with_timestamp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare gold data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3016, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_input_data_path = '../temp_training/medallion/gold/gold_COMBINED.xlsx'\n",
    "inference_df = pd.read_excel(inference_input_data_path)\n",
    "inference_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TOPIC                 RELEVANCE_CLASS\n",
       "air                   -1                  51\n",
       "                       0                 119\n",
       "                       1                 146\n",
       "cybersecurity         -1                   2\n",
       "forced_labor          -1                   3\n",
       "                       1                   1\n",
       "marine                 0                 190\n",
       "                       1                 134\n",
       "maritime              -1                  56\n",
       "                       0                   7\n",
       "                       1                  11\n",
       "material               0                 118\n",
       "                       1                   3\n",
       "protest_riot           0                 421\n",
       "                       1                  39\n",
       "road                   0                  22\n",
       "strike                 0                 189\n",
       "                       1                  23\n",
       "train                 -1                 134\n",
       "                       0                  85\n",
       "                       1                 156\n",
       "warehouse_fire        -1                  95\n",
       "                       0                 104\n",
       "                       1                 145\n",
       "weather               -1                 262\n",
       "weather_cyclone        0                   7\n",
       "                       1                   6\n",
       "weather_generalnews    0                 109\n",
       "                       1                 145\n",
       "weather_naturalevent   0                 187\n",
       "                       1                  46\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_df.groupby(['TOPIC','RELEVANCE_CLASS']).size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Listing the experiments recorded "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> use one for sampling new codes, one for full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='file:///c:/Users/JOSHUALE/Documents/Github/mlflow_tutorial/experiments/mlruns/227815192018524595', creation_time=1697818753176, experiment_id='227815192018524595', last_update_time=1697818753176, lifecycle_stage='active', name='zero_shot_prediction_L14D_001', tags={}>,\n",
       " <Experiment: artifact_location='file:///c:/Users/JOSHUALE/Documents/Github/mlflow_tutorial/experiments/mlruns/677968303451148623', creation_time=1697816832103, experiment_id='677968303451148623', last_update_time=1697816832103, lifecycle_stage='active', name='zero_shot_prediction_001', tags={}>,\n",
       " <Experiment: artifact_location='file:///c:/Users/JOSHUALE/Documents/Github/mlflow_tutorial/experiments/mlruns/0', creation_time=1697816832085, experiment_id='0', last_update_time=1697816832085, lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENT_NAME = \"zero_shot_prediction\"\n",
    "# EXPERIMENT_ID = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "mlflow.search_experiments()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample experiment on small df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started run: cdb489738fe74707b16ee5f81f00aa7a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a001d16732f543fa92fd5ada60bddae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for sample experiment:\n",
    "EXPERIMENT_ID = '677968303451148623'\n",
    "RUN_DESCRIPTION = ''\n",
    "with mlflow.start_run(experiment_id=EXPERIMENT_ID, description=RUN_DESCRIPTION) as run:\n",
    "    RUN_ID = run.info.run_id\n",
    "    print(f\"Started run: {RUN_ID}\")\n",
    "    # change path accordingly\n",
    "    class_labels_data_path = '../data/input/class_label_by_topic.csv'\n",
    "    class_labels_data = pd.read_csv(class_labels_data_path)\n",
    "    candidate_labels = list(class_labels_data['CLASS_DESCRIPTION'])\n",
    "\n",
    "    inference_df = pd.read_csv(inference_input_data_path)\n",
    "    inference_df = inference_df.sample(5, random_state=99) # getting a sample only\n",
    "\n",
    "    model_path = '../models/pretrained/bart-large-mnli/'\n",
    "    loaded_classifier = pipeline(\"zero-shot-classification\", model=model_path)\n",
    "    \n",
    "    mlflow.log_param(\"model_path\", model_path)\n",
    "    mlflow.log_artifact(class_labels_data_path, \"class_labels_data\")\n",
    "    mlflow.log_artifact(inference_input_data_path, \"inference_input_data\")\n",
    "    \n",
    "    inference_df['ZERO_SHOT_PREDICTION'] = inference_df.progress_apply(lambda row: \n",
    "                                                   zero_shot_predict_single_model(\n",
    "                                                       classifier=loaded_classifier, \n",
    "                                                       sequence_to_classify=row['BODY_SUMMARY'], \n",
    "                                                       candidate_labels=candidate_labels), \n",
    "                                                    axis=1)\n",
    "    inference_df['FIRST_PREDICTION_CLASS'] = inference_df['ZERO_SHOT_PREDICTION'].apply(lambda result_dict: get_top_n_label_and_score(result_dict, 1)[0])\n",
    "    inference_df['FIRST_PREDICTION_SCORE'] = inference_df['ZERO_SHOT_PREDICTION'].apply(lambda result_dict: get_top_n_label_and_score(result_dict, 1)[1])\n",
    "    inference_df['SECOND_PREDICTION_CLASS'] = inference_df['ZERO_SHOT_PREDICTION'].apply(lambda result_dict: get_top_n_label_and_score(result_dict, 2)[0])\n",
    "    inference_df['SECOND_PREDICTION_SCORE'] = inference_df['ZERO_SHOT_PREDICTION'].apply(lambda result_dict: get_top_n_label_and_score(result_dict, 2)[1])\n",
    "    # Save the DataFrame to a CSV file\n",
    "    current_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    predictions_path = f\"./output/temp_mlflow/zero_shot_prediction_{current_datetime}.csv\"\n",
    "    inference_df.to_csv(predictions_path, index=False)\n",
    "    # Log the CSV file as an artifact\n",
    "    mlflow.log_artifact(predictions_path, f\"zero_shot_prediction\")\n",
    "mlflow.end_run() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started run: 431def949bda4214a597e04b53ad217c\n",
      "Candidate labels in use:\n",
      "['very recent breaking news on major railway transportation disruption, bad news', 'very recent breaking news on major maritime transportation disruption, bad news', 'very recent breaking news on warehouse and storage facilities disruption or destruction, bad news', 'very recent breaking news on major air transportation or airport disruption, bad news', 'very recent breaking news on severe and extreme weather causing disruption, bad news ', 'very recent breaking news on major and large scale worker strike actions causing disruption, bad news', 'very recent breaking news on major and large scale cyber attacks and security breaches, bad news', 'very recent breaking news on forced labor and sweatshop', 'later reports of past transportation disruption event, bad news', 'lawsuits, legal or insurance impact of past event, bad news', 'general social, business, economic reports, studies and trends', 'leisure or other news']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17bad588d5ec4c0aa7862ef95004f9a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for time consuming experiment:\n",
    "EXPERIMENT_ID = '227815192018524595'\n",
    "RUN_DESCRIPTION = ''\n",
    "with mlflow.start_run(experiment_id=EXPERIMENT_ID, description=RUN_DESCRIPTION) as run:\n",
    "    RUN_ID = run.info.run_id\n",
    "    print(f\"Started run: {RUN_ID}\")\n",
    "    # change path accordingly\n",
    "    class_labels_data_path = '../data/input/class_label_by_topic.csv'\n",
    "    class_labels_data = pd.read_csv(class_labels_data_path)\n",
    "    candidate_labels = list(class_labels_data['CLASS_DESCRIPTION'])\n",
    "    print(\"Candidate labels in use:\")\n",
    "    print(candidate_labels)\n",
    "\n",
    "    inference_df = pd.read_csv(inference_input_data_path)\n",
    "    # inference_df = inference_df.sample(5, random_state=99) # getting a sample only\n",
    "\n",
    "    model_path = '../models/pretrained/bart-large-mnli/'\n",
    "    loaded_classifier = pipeline(\"zero-shot-classification\", model=model_path)\n",
    "    \n",
    "    mlflow.log_param(\"model_path\", model_path)\n",
    "    mlflow.log_artifact(class_labels_data_path, \"class_labels_data\")\n",
    "    mlflow.log_artifact(inference_input_data_path, \"inference_input_data\")\n",
    "    \n",
    "    inference_df['ZERO_SHOT_PREDICTION'] = inference_df.progress_apply(lambda row: \n",
    "                                                   zero_shot_predict_single_model(\n",
    "                                                       classifier=loaded_classifier, \n",
    "                                                       sequence_to_classify=row['BODY_SUMMARY'], \n",
    "                                                       candidate_labels=candidate_labels), \n",
    "                                                    axis=1)\n",
    "    inference_df['FIRST_PREDICTION_CLASS'] = inference_df['ZERO_SHOT_PREDICTION'].apply(lambda result_dict: get_top_n_label_and_score(result_dict, 1)[0])\n",
    "    inference_df['FIRST_PREDICTION_SCORE'] = inference_df['ZERO_SHOT_PREDICTION'].apply(lambda result_dict: get_top_n_label_and_score(result_dict, 1)[1])\n",
    "    inference_df['SECOND_PREDICTION_CLASS'] = inference_df['ZERO_SHOT_PREDICTION'].apply(lambda result_dict: get_top_n_label_and_score(result_dict, 2)[0])\n",
    "    inference_df['SECOND_PREDICTION_SCORE'] = inference_df['ZERO_SHOT_PREDICTION'].apply(lambda result_dict: get_top_n_label_and_score(result_dict, 2)[1])\n",
    "    inference_df['THIRD_PREDICTION_CLASS'] = inference_df['ZERO_SHOT_PREDICTION'].apply(lambda result_dict: get_top_n_label_and_score(result_dict, 3)[0])\n",
    "    inference_df['THIRD_PREDICTION_SCORE'] = inference_df['ZERO_SHOT_PREDICTION'].apply(lambda result_dict: get_top_n_label_and_score(result_dict, 3)[1])\n",
    "    # Save the DataFrame to a CSV file\n",
    "    current_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    predictions_path = f\"./output/temp_mlflow/zero_shot_prediction_{current_datetime}.csv\"\n",
    "    inference_df.to_csv(predictions_path, index=False)\n",
    "    # Log the CSV file as an artifact\n",
    "    mlflow.log_artifact(predictions_path, f\"zero_shot_prediction\")\n",
    "mlflow.end_run() \n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For adding more n-th pred score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast \n",
    "\n",
    "inference_df = pd.read_csv('./output/temp_mlflow/zero_shot_prediction_L14D.csv')\n",
    "inference_df['ZERO_SHOT_PREDICTION'] = inference_df['ZERO_SHOT_PREDICTION'].apply(ast.literal_eval)\n",
    "inference_df['FIRST_PREDICTION_CLASS'] = inference_df['ZERO_SHOT_PREDICTION'].apply(lambda result_dict: get_top_n_label_and_score(result_dict, 1)[0])\n",
    "inference_df['FIRST_PREDICTION_SCORE'] = inference_df['ZERO_SHOT_PREDICTION'].apply(lambda result_dict: get_top_n_label_and_score(result_dict, 1)[1])\n",
    "inference_df['SECOND_PREDICTION_CLASS'] = inference_df['ZERO_SHOT_PREDICTION'].apply(lambda result_dict: get_top_n_label_and_score(result_dict, 2)[0])\n",
    "inference_df['SECOND_PREDICTION_SCORE'] = inference_df['ZERO_SHOT_PREDICTION'].apply(lambda result_dict: get_top_n_label_and_score(result_dict, 2)[1])\n",
    "inference_df['THIRD_PREDICTION_CLASS'] = inference_df['ZERO_SHOT_PREDICTION'].apply(lambda result_dict: get_top_n_label_and_score(result_dict, 3)[0])\n",
    "inference_df['THIRD_PREDICTION_SCORE'] = inference_df['ZERO_SHOT_PREDICTION'].apply(lambda result_dict: get_top_n_label_and_score(result_dict, 3)[1])\n",
    "\n",
    "current_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "predictions_path = f\"./output/temp_mlflow/zero_shot_prediction_{current_datetime}.csv\"\n",
    "inference_df.to_csv(predictions_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "286bc12fa30b74ef856228bed3e3c37bde5be697e37af5195e71bc249a2a5043"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
